{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DivyaRustagi10/contextualized-topic-models-ssl/blob/main/ZeroshotTM_For_Same_Script_Languages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-shot Cross-Lingual Topic Modeling For Same Script Languages\n",
        "> Do conxtextualized TM tackle zero-shot cross-lingual topic modeling better on same script languages?\n",
        "\n",
        "We use 4000 documents as training and consider randomly sampled 800 documents as the test set. We collect the 800 respective instances in [LANGUAGES].\n",
        "\n",
        "First, we use IndicBERT to generate multilingual embeddings as the input of the model. Then we evaluate multilingual topic predictions on the multilingual abstracts in test set."
      ],
      "metadata": {
        "id": "Te7oLPMkvQR_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M3H5Cn_ftZzW"
      },
      "outputs": [],
      "source": [
        "# Install the contextualized topic model library\n",
        "%%capture\n",
        "!pip install -U contextualized_topic_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Vht2fQJ6uqvh"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyldavis\n",
        "!pip install wget\n",
        "!pip install head\n",
        "!nvidia-smi\n",
        "\n",
        "# Setup Hindi for analysis\n",
        "!pip install indic-nlp-library==0.81\n",
        "!pip install stopwordsiso\n",
        "!pip install torch==1.3.1+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install inltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yTkSBfbBq25Z"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from contextualized_topic_models.models.ctm import ZeroShotTM\n",
        "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
        "from contextualized_topic_models.utils.preprocessing import  WhiteSpacePreprocessingStopwords\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from inltk.inltk import setup\n",
        "\n",
        "try:\n",
        "  setup('hi')\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "zaM6lH0GjDsR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVPQoVENZ-mr"
      },
      "source": [
        "## Data\n",
        "\n",
        "###**Building PMIndia Corpus**\n",
        "\n",
        "Below contains the code for creating a parallel corpus from the website of the Indian Prime Minister (www.pmindia.gov.in). \n",
        "\n",
        "We combine each speech document into one, for every language. Datasets are downloaded from [Statistical Machine Translation](https://data.statmt.org/pmindia/v1/monolingual/)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Downloading Dataset*"
      ],
      "metadata": {
        "id": "VaEkTabsl9ef"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AXdZmkuJbo4p"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import urllib\n",
        "import wget\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Download PMIndia Datasets\n",
        "FILES_DIR = os.getcwd() # REPLACE WITH YOUR DIRECTORY IF YOU PREFER DOWNLOADING IN SPECIFIC DIRECTORY\n",
        "LINK = \"https://drive.google.com/u/0/uc?id=1IqH2XQFw1XHPT2Sh_Yz3LnrMEVqS8oef&export=download\"  # LINK TO PMINDIA FILE LOCATION\n",
        "FILE_PATH = os.getcwd() + \"/\" + wget.download(LINK) # PATH TO DOWNLOADS\n",
        "\n",
        "pmindia_list = pd.read_csv(FILE_PATH, sep = \",\",  names = [\"lang\", \"link\"], engine = \"python\" )['link']\n",
        "pmindia_list = [FILES_DIR + \"/\" + wget.download(link.strip(\" \")) for link in pmindia_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VtaE0KjRR7qf"
      },
      "outputs": [],
      "source": [
        "# Build directory to store speech files\n",
        "%%bash\n",
        "mkdir parallel_speeches\n",
        "cd parallel_speeches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "prkgcgs6ITdQ"
      },
      "outputs": [],
      "source": [
        "# Files stored in content directory\n",
        "# Data will need to be re-downloaded if a session closes\n",
        "''' Following script will download parallel corpus into new directory named parallel_speeches.\n",
        "Each folder in parallel_speeches contains pmindia speeches in indic language identified by their ISO code.\n",
        "\n",
        "For e.g.\n",
        "parallel_speeches/as/ contains speeches in Assamese.\n",
        "parallel_speeches/hi contains speeches in Hindi.\n",
        "'''\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "FILES_DIR = os.getcwd() # REPLACE WITH DIRECTORY OF FILES\n",
        "STORE_FILES_HERE = os.getcwd() + \"/parallel_speeches\" # STORE EXTRACTED FILES HERE\n",
        "\n",
        "for fname in pmindia_list:\n",
        "    tar = tarfile.open(fname, \"r:gz\") # unzip file\n",
        "    tar.extractall(STORE_FILES_HERE)    \n",
        "    foldername = fname[fname.rfind('.tgz')-2: fname.rfind('.tgz')] # get folder name\n",
        "    os.rename(STORE_FILES_HERE + \"/split\", STORE_FILES_HERE + \"/\" + foldername) # rename default split folder to language name\n",
        "    tar.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Get Parallel Speeches*"
      ],
      "metadata": {
        "id": "8tVllbDgmERy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HT0AkExw3D8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a235acb-2042-48d3-9704-627abe000d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Model. This might take time, depending on your internet connection. Please be patient.\n",
            "We'll only do this for the first time.\n"
          ]
        }
      ],
      "source": [
        "import glob # SEEK FILES FROM ABOVE FOR DOWNLOAD\n",
        "FOLDERS_DIR = os.getcwd() + \"/parallel_speeches\"  # DIRECTORY FOR SAVING PARALLEL SPEECHES\n",
        "\n",
        "# Stores list of speeches in dictionary keyed by ISO language name\n",
        "SPEECHES_IN_LANGS = {languagefolder[-2:] : sorted(list(glob.glob(languagefolder + \"/*.txt\")))[3:] for languagefolder in glob.glob(FOLDERS_DIR + \"/*\")}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get file names to find common test corpus (set of files common between all languages)\n",
        "STRIP_INDEX = SPEECHES_IN_LANGS['as'][0].index('as') + len('as/')   # GET LANGUAGE ISO CODE\n",
        "\n",
        "filenames = {}\n",
        "for lang in SPEECHES_IN_LANGS.keys():\n",
        "  temp = [item[STRIP_INDEX:] for item in SPEECHES_IN_LANGS[lang]]\n",
        "  filenames[lang] = temp"
      ],
      "metadata": {
        "id": "VGe718ULoiWJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Combine Parallel Speeches Into Corpus*"
      ],
      "metadata": {
        "id": "JALisreCmu77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting seed for reproducibility\n",
        "import random\n",
        "random.seed(210)\n",
        "\n",
        "# Select 800 random corpus\n",
        "sample_corpus = sorted(random.sample(list(set.intersection(*map(set, filenames.values()))), 800))\n",
        "pd.DataFrame(sample_corpus, columns = [\"Speech File Name\"])"
      ],
      "metadata": {
        "id": "lecI86aHVEEx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "e18197f5-4114-4986-cacb-7ca066b70621"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      Speech File Name\n",
              "0    15th-edition-of-pravasi-bharatiya-diwas-inaugu...\n",
              "1    ambassador-ms-nikki-haley-united-states-perman...\n",
              "2    anganwadi-workers-from-across-the-country-call...\n",
              "3    asha-representatives-from-across-the-country-c...\n",
              "4    beneficiaries-of-pradhan-mantri-mudra-yojana-s...\n",
              "..                                                 ...\n",
              "795  the-budget-for-new-india-will-energise-the-nat...\n",
              "796  uk-india-joint-statement-during-pms-visit-to-u...\n",
              "797      up-cm-donates-rs-five-crore-towards-pmnrf.txt\n",
              "798  us-secretary-of-state-rex-w-tillerson-calls-on...\n",
              "799  visit-of-president-of-islamic-republic-of-afgh...\n",
              "\n",
              "[800 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c6ccbd9-1561-4f46-903e-78f54a85a787\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Speech File Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15th-edition-of-pravasi-bharatiya-diwas-inaugu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ambassador-ms-nikki-haley-united-states-perman...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>anganwadi-workers-from-across-the-country-call...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>asha-representatives-from-across-the-country-c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>beneficiaries-of-pradhan-mantri-mudra-yojana-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>the-budget-for-new-india-will-energise-the-nat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>uk-india-joint-statement-during-pms-visit-to-u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>up-cm-donates-rs-five-crore-towards-pmnrf.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>us-secretary-of-state-rex-w-tillerson-calls-on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>visit-of-president-of-islamic-republic-of-afgh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c6ccbd9-1561-4f46-903e-78f54a85a787')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c6ccbd9-1561-4f46-903e-78f54a85a787 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c6ccbd9-1561-4f46-903e-78f54a85a787');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_HLUyqCLifq1"
      },
      "outputs": [],
      "source": [
        "# Combine selected 800 sample speeches into one document for each lang \n",
        "parallel_speeches = {}    # STORE TEST SPEECHES\n",
        "train_speeches = {}       # STORE TRAIN SPEECHES\n",
        "\n",
        "for lang, speeches in SPEECHES_IN_LANGS.items(): \n",
        "  each_lang = []         # list of speeches for one language at a time\n",
        "  just_train = []\n",
        "  \n",
        "  for speech_file in speeches:                          # access list of files in speeches for one language at a time\n",
        "    with open(speech_file, 'r') as speech:              # read file\n",
        "      speech = \" \".join([str(line) for line in speech]) # each speech file becomes one string\n",
        "\n",
        "      if speech_file[STRIP_INDEX:] in sample_corpus:\n",
        "        each_lang.append(speech)                        # append string version of speech file\n",
        "      else:\n",
        "        just_train.append(speech)                       # add to train set\n",
        "\n",
        "  parallel_speeches[lang] = each_lang                   # add list of speeches for every language\n",
        "  train_speeches[lang] = just_train                     # add to train set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Split Parallel Corpus Into Test and Train*"
      ],
      "metadata": {
        "id": "_vkfxcP4mk-W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PMPHUR_D4f9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f1f49af-f397-464b-8715-38b17e351ace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   0\n",
            "0  नागरिकों से स्‍वच्‍छाग्रही बनने और स्‍वच्‍छ भा...\n",
            "1  श्री सोमनाथ न्‍यास के न्‍यासियों की 116वीं बैठ...\n",
            "2  प्रधानमंत्री श्री नरेन्द्र मोदी की अध्यक्षता म...\n",
            "3  प्रधानमंत्री श्री नरेन्द्र मोदी ने आज ही के दि...\n",
            "4  · खूंटी की जिला अदालत में छत पर लगने वाले सौर ...\n",
            "                                                   0\n",
            "0  PM Calls upon citizens to become Swachhagrahis...\n",
            "1  The first 10 months of Prime Minister Narendra...\n",
            "2  BRICS in Africa: Collaboration for Inclusive G...\n",
            "3  The 116th meeting of the trustees of Shri Somn...\n",
            "4  Deendayal Upadhyaya Gram Jyoti Yojana\\n The Un...\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "import re\n",
        "\n",
        "# Selecting Train speeches\n",
        "hindi_unprep = pd.DataFrame(list for list in train_speeches['hi'])\n",
        "english_unprep = pd.DataFrame(list for list in train_speeches['en'])\n",
        "\n",
        "# We select speeches with at least 500 tokens\n",
        "# TOKENS_LIMIT = 500\n",
        "# remove = []\n",
        "# for speech in hindi_unprep[:5].itertuples():\n",
        "#   if len(speech[1].split(\" \"))  < TOKENS_LIMIT:\n",
        "#     remove.append(speech[0])\n",
        "#     print(speech[0], \" removed!\")\n",
        "\n",
        "# View each row as a speech\n",
        "print(hindi_unprep[:5])\n",
        "print(english_unprep[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Models"
      ],
      "metadata": {
        "id": "vEcvJVNDnF02"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "erO2thoszs7P"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from contextualized_topic_models.models.ctm import ZeroShotTM\n",
        "import contextualized_topic_models.utils.data_preparation\n",
        "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
        "from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessing\n",
        "import nltk\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import string\n",
        "from nltk.corpus import stopwords as stop_words\n",
        "from gensim.utils import deaccent\n",
        "import warnings\n",
        "from inltk.inltk import remove_foreign_languages\n",
        "\n",
        "\n",
        "class WhiteSpacePreprocessingStopwords(WhiteSpacePreprocessingStopwords):\n",
        "    \"\"\"\n",
        "    Overriden author's original code to keep accents during preprocessing.\n",
        "    Provides a very simple preprocessing script that filters infrequent tokens from text\n",
        "    \"\"\"\n",
        "    def preprocess(self):\n",
        "        \"\"\"\n",
        "        Note that if after filtering some documents do not contain words we remove them. That is why we return also the\n",
        "        list of unpreprocessed documents.\n",
        "        :return: preprocessed documents, unpreprocessed documents and the vocabulary list\n",
        "        \"\"\"\n",
        "        from indicnlp.tokenize import indic_tokenize \n",
        "\n",
        "        preprocessed_docs_tmp = self.documents\n",
        "\n",
        "        # REMOVE DEACCENT\n",
        "        preprocessed_docs_tmp = [doc.lower() for doc in preprocessed_docs_tmp]\n",
        "        preprocessed_docs_tmp = [doc.translate(\n",
        "            str.maketrans(string.punctuation, ' ' * len(string.punctuation))) for doc in preprocessed_docs_tmp]\n",
        "\n",
        "        if self.remove_numbers:\n",
        "            preprocessed_docs_tmp = [doc.translate(str.maketrans(\"0123456789\", ' ' * len(\"0123456789\")))\n",
        "                                     for doc in preprocessed_docs_tmp]\n",
        "\n",
        "        # REMOVE PUNCTUATION CHARACTERS NOT COVERED BY string.punctuation                             \n",
        "        preprocessed_docs_tmp = [doc.translate(\n",
        "            str.maketrans(\"_–‘’\\'':.,*।\\n\", ' ' * len(\"_–‘’\\'':.,*।\\n\"))) for doc in preprocessed_docs_tmp]\n",
        "                                               \n",
        "        # REPLACED COUNTVECTORIZER WITH INDIC TOKENIZE'S TRIVIAL TOKENIZATION \n",
        "        preprocessed_docs_tmp = [' '.join([w for w in indic_tokenize.trivial_tokenize(doc) if len(w) > 0 and w not in self.stopwords]) for doc in preprocessed_docs_tmp]\n",
        "\n",
        "        preprocessed_docs, unpreprocessed_docs, retained_indices = [], [], []\n",
        "        for i, doc in enumerate(preprocessed_docs_tmp):\n",
        "            if len(doc) > 0 and len(doc) >= self.min_words:\n",
        "                preprocessed_docs.append(doc)\n",
        "                unpreprocessed_docs.append(self.documents[i])\n",
        "                retained_indices.append(i)\n",
        "\n",
        "        vocabulary = list(set([item for doc in preprocessed_docs for item in doc.split()]))\n",
        "\n",
        "        return preprocessed_docs, unpreprocessed_docs, vocabulary, retained_indices"
      ],
      "metadata": {
        "id": "nbFHdpLD-f4G"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Hindi-Based ZeroshotTM**\n",
        "\n",
        "*Preprocessing*\n",
        "\n",
        "Why do we use the preprocessed text here? We need text without punctuation to build the bag of word. Also, we might want only to have the most frequent words inside the BoW. Too many words might not help."
      ],
      "metadata": {
        "id": "w7NsHKg2WXZS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sQBKiAC_z_aj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2421c867-a2e3-4008-a25e-5d8a19351a6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4003 4003\n"
          ]
        }
      ],
      "source": [
        "### HINDI ###\n",
        "LANG_SELECTED = 'hi'\n",
        "\n",
        "# We select 500 tokens per speech\n",
        "NUM_TOKENS = 500\n",
        "\n",
        "# Import Hindi Stopwords\n",
        "import stopwordsiso as stopwords\n",
        "\n",
        "# Run preprocessing script\n",
        "documents = [line[:NUM_TOKENS].strip() for line in train_speeches[LANG_SELECTED]]\n",
        "sp = WhiteSpacePreprocessingStopwords(documents, stopwords_list = stopwords.stopwords(LANG_SELECTED))\n",
        "preprocessed_documents, unpreprocessed_corpus, vocab, __= sp.preprocess()\n",
        "\n",
        "# Ensure same length for preprocessed and unpreprocessed\n",
        "print(len(preprocessed_documents), len(unpreprocessed_corpus))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "pprint(preprocessed_documents[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHgQLW0hZwjS",
        "outputId": "44e86992-3134-450d-f927-a34163596808"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['नागरिकों स्\\u200dवच्\\u200dछाग्रही बनने स्\\u200dवच्\\u200dछ भारत बनाने आह्वान '\n",
            " 'प्रधानमंत्री श्री नरेन्\\u200dद्र मोदी चंपारण महात्\\u200dमा गांधी '\n",
            " 'सत्\\u200dयाग्रह प्रयोग साल पूरे अवसर राष्\\u200dट्रीय राजधानी कल '\n",
            " 'स्\\u200dवच्\\u200dछाग्रह बापू करयां\\u200dजलि अभियान प्रदर्शनी उद्घाटन करेंगे '\n",
            " 'दौरान भारतीय राष्\\u200dट्रीय अभिलेखागार आयोजित ऑनलाइन इंटरएक्टिव क्विज '\n",
            " 'शुभारंभ करेंगे प्रधानमंत्री ट्वीट्स श्रृंखला बारे बताते चंपारण '\n",
            " 'सत्\\u200dयाग्रह ऐ',\n",
            " 'श्री सोमनाथ न्\\u200dयास न्\\u200dयासियों वीं बैठक आज सोमनाथ '\n",
            " 'सम्\\u200dपन्\\u200dन बैठक न्\\u200dयासियों प्रधानमंत्री श्री नरेंद्र मोदी श्री '\n",
            " 'लालकृष्\\u200dण आडवाणी श्री अमित शाह श्री केशू भाई पटेल श्री पी लाहडी श्री जे '\n",
            " 'डी परमार श्री हर्ष नेवतिया भाग लिया बैठक श्री नरेन्\\u200dद्र मोदी सुझाव श्री '\n",
            " 'सोमनाथ मंदिर सम्\\u200dपूर्ण परिसर जल हरियाली अन्\\u200dय सुविधाओं '\n",
            " 'उन्\\u200dनयन जाए उन्\\u200dहोंने सिफारिश वेरावल प्रभास पाटन नकदी रहित बनाने '\n",
            " 'न्\\u200dयास सक्र',\n",
            " 'प्रधानमंत्री श्री नरेन्द्र मोदी अध्यक्षता मंत्रीमंडल बैठक दीनदयाल उपाध्याय '\n",
            " 'ग्राम ज्योति योजना डीडीयूजीजेवाई प्रारंभ आज अनुमति दी गई योजना तहत ग्रामीण '\n",
            " 'क्षेत्रों कृषि गैर कृषि उपभोक्ताओं विवेकपूर्ण तरीके विद्युत आपूर्ति '\n",
            " 'सुनिश्चित सुलभ बनाने कृषि गैर कृषि फीडर सुविधाओं अलग अलग जाएगा ग्रामीण '\n",
            " 'क्षेत्रों वितरण उप पारेषण प्रणाली मजबूत जाएगा जिसमें वितरण ट्रांसफार्मर फीडर '\n",
            " 'उपभोक्\\u200dताओं मीटर लगा',\n",
            " 'प्रधानमंत्री श्री नरेन्द्र मोदी आज दिन मुंबई आतंकी हमलों दौरान शहीद '\n",
            " 'सुरक्षाकर्मियों सलाम जिन्होंने दूसरों जिंदगी बचाने प्राणों आहूति दे दी '\n",
            " 'उन्होंने आतंकवाद सख्ती निपटने भारत संकल्प दोहराया प्रधानमंत्री “मुंबई भयावह '\n",
            " 'आतंकी हमलों याद हम बेगुनाह लोगों श्रद्धांजलि अर्पित जिन्होंने हमले जान खो दी '\n",
            " 'हम बहादुर सुरक्षाकर्मियों सलाम',\n",
            " '· खूंटी जिला अदालत छत लगने सौर ऊर्जा संयंत्र उद्घाटन · प्रधानमंत्री मुद्रा '\n",
            " 'योजना विशाल ऋण शिविर उद्घाटन दुमका चयनित लाभार्थियों ऋण दस्तावेज मुद्रा '\n",
            " 'कार्ड सौंपा · चयनित बीपीएल परिवारों नए एलपीजी कनेक्शन सौंपे · ऐतिहासिक मलूती '\n",
            " 'मंदिर परिसर संरक्षण विकास कार्यों शुरुआत प्रधानमंत्री नरेन्द्र मोदी आज '\n",
            " 'झारखंड खूंटी जिला अदालत परिसर छत लगने केवी क्षमता सौर ऊर्जा संयंत्र उद्घाटन '\n",
            " 'अवसर विशाल सभ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnIptVxk0F4n"
      },
      "source": [
        "We don't discard the non-preprocessed hindi texts, because we are going to use them as input for obtaining the **contextualized** document representations. We will now pass our files with preprocess and unpreprocessed data to our TopicModelDataPreparation object. This object takes care of creating the bag of words and obtains the contextualized BERT representations of documents. This operation allows us to create our training dataset.\n",
        "\n",
        "Note: Here we use the contextualized model \"ai4bharat/indic-bert\", because we need a multilingual model for indic languages for performing cross-lingual predictions later.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5dx85bGx7eu"
      },
      "source": [
        "*Training ZeroshotTM*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Override utility functions for TopicModelDataPreparation to support SentenceTransformers built from scratch\n",
        "from sentence_transformers import SentenceTransformer, models\n",
        "import numpy as np\n",
        "\n",
        "def bert_embeddings_from_file(text_file, sbert_model_to_load, custom=False, tokenizer_args=None, model_args=None, batch_size=200):\n",
        "    \"\"\"\n",
        "    Creates SBERT Embeddings from an input file\n",
        "    \"\"\"\n",
        "    from sentence_transformers import SentenceTransformer, models\n",
        "\n",
        "    # For indicBERT\n",
        "    if sbert_model_to_load == 'ai4bharat/indic-bert':\n",
        "      custom = True\n",
        "      tokenizer_args = {\"keep_accents\": True}\n",
        "\n",
        "    # If build custom sentence transformer model\n",
        "    if custom is True:\n",
        "      if tokenizer_args and model_args:   # both set of arguments given in dict to pass into hugging face model\n",
        "        word_embedding_model = models.Transformer(sbert_model_to_load, \n",
        "                                                  tokenizer_args=tokenizer_args, \n",
        "                                                  model_args = model_args)\n",
        "      \n",
        "      elif tokenizer_args:   # tokenizer arguments given in dict to pass into hugging face model\n",
        "        word_embedding_model = models.Transformer(sbert_model_to_load, tokenizer_args = tokenizer_args)\n",
        "\n",
        "      elif model_args:   # model arguments given in dict to pass into hugging face model\n",
        "        word_embedding_model = models.Transformer(sbert_model_to_load, model_args = model_args)\n",
        "      \n",
        "      else:\n",
        "        word_embedding_model = models.Transformer(sbert_model_to_load)\n",
        "\n",
        "      # Pass modules to build sentence transformer model\n",
        "      pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
        "      model = SentenceTransformer(modules=[word_embedding_model, pooling_model])   \n",
        "    \n",
        "    # Else retrieve model from hugging face\n",
        "    else:\n",
        "        model = SentenceTransformer(sbert_model_to_load)\n",
        "\n",
        "    with open(text_file, encoding=\"utf-8\") as filino:\n",
        "        train_text = list(map(lambda x: x, filino.readlines()))\n",
        "\n",
        "    return np.array(model.encode(train_text, show_progress_bar=True, batch_size=batch_size))\n",
        "\n",
        "\n",
        "def bert_embeddings_from_list(texts, sbert_model_to_load, custom=False, tokenizer_args=None, model_args=None, batch_size=200):\n",
        "    \"\"\"\n",
        "    Creates SBERT Embeddings from a list\n",
        "    \"\"\"\n",
        "    from sentence_transformers import SentenceTransformer, models\n",
        "\n",
        "    # For indicBERT\n",
        "    if sbert_model_to_load == 'ai4bharat/indic-bert':\n",
        "      custom = True\n",
        "      tokenizer_args = {\"keep_accents\": True}\n",
        "\n",
        "    # If build custom sentence transformer model\n",
        "    if custom is True:\n",
        "      if tokenizer_args and model_args:   # both set of arguments given in dict to pass into hugging face model\n",
        "        word_embedding_model = models.Transformer(sbert_model_to_load, \n",
        "                                                  tokenizer_args=tokenizer_args, \n",
        "                                                  model_args = model_args)\n",
        "      \n",
        "      elif tokenizer_args:   # tokenizer arguments given in dict to pass into hugging face model\n",
        "        word_embedding_model = models.Transformer(sbert_model_to_load, tokenizer_args = tokenizer_args)\n",
        "\n",
        "      elif model_args:   # model arguments given in dict to pass into hugging face model\n",
        "        word_embedding_model = models.Transformer(sbert_model_to_load, model_args = model_args)\n",
        "      \n",
        "      else:\n",
        "        word_embedding_model = models.Transformer(sbert_model_to_load)\n",
        "\n",
        "      # Pass modules to build sentence transformer model\n",
        "      pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
        "      model = SentenceTransformer(modules=[word_embedding_model, pooling_model])   \n",
        "\n",
        "    # Else retrieve model from hugging face\n",
        "    else:\n",
        "        model = SentenceTransformer(sbert_model_to_load)\n",
        "\n",
        "    return np.array(model.encode(texts, show_progress_bar=True, batch_size=batch_size))\n",
        "\n",
        "contextualized_topic_models.utils.data_preparation.bert_embeddings_from_file = bert_embeddings_from_file\n",
        "contextualized_topic_models.utils.data_preparation.bert_embeddings_from_list = bert_embeddings_from_list\n"
      ],
      "metadata": {
        "id": "Qs4qdAdEiSgM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GO-88XsA0G6m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251,
          "referenced_widgets": [
            "8e23eb79e4164c3e8255377c63c148f4",
            "8f775ea37dee45dca3bffb64eff854a0",
            "a91e61e3c1d940ddadf35de30dfb7fa0",
            "ec8f81d5a5524203a4c367b043d6e614",
            "dd2f6d3ccd9b4afea63498ecfbaca480",
            "8c3f57776e9f4942a4c82a304af5edf5",
            "c81a3e083f0143218297ac5dfe71debb",
            "3d9ffb7eb5b1431ebc839c99f0f77e53",
            "6e3f423ca41946ec924985017bfec049",
            "79de7bbdf8f942f4b429dff85d75d725",
            "2b0a015dee53491dbb474ea756f657a3",
            "87a0c90d741a49028a60d3c80be24091",
            "1769c50f497649a682960530f3879e64",
            "4c02146948c049db98bb33eaeec3365a",
            "8ea6c41758874ed98a5cdc2cef0ba970",
            "ee4f46cab385467ab4a876e9ef680ba8",
            "0904d5bd060447c88aedfdc8945265f4",
            "e5523aa1aff0463aaa94f413529df362",
            "abb138bc00ac40099e8aec99aff3d2ad",
            "0a95aba2b373469ba968bc0fb1a6449d",
            "c79e1a2958ad43e180f294dc052be80e",
            "f9a92e9814a74dc6b1decf03a595cbfa",
            "103e4f9ffc914a81919ccb648cb202d8",
            "9fe82bfe1d864c86a90e9dc3516b6d90",
            "513981a1cfb641279b8725678956a8ab",
            "57775ccab6214451acae604cad51311e",
            "730a4eaa85434a6690b7712ba13d0293",
            "9e3ae0d15abc41bb94f4f3fd49bab2ac",
            "503a228fc2a941659a7e45d7aadeaff4",
            "63c4e50b6ff240dba2a34a7ab8fceb01",
            "4212f5bb16794dd59581c7c9cee9e16d",
            "3740be0359c14284ad2733df42dc8183",
            "ce97ac1976714856be74dfd818b0d62d",
            "1c19075abef54e8c87ad89fa1f4765e0",
            "f27cb8c71d1d47b295890ae04060c4be",
            "13091ff199624ec884a09eef0f4c4d7e",
            "405785406f7448b9a6c25f3f5b892990",
            "c5383cb9621c467ea9b1c8f5a82a6387",
            "7061ce2b0e43401784483cf53b5e6861",
            "2748034910894f98904a8ee1680cab35",
            "22e114a6afcc4b06ae55551ecc32858c",
            "e25e85b678c749dd954c07bcee9cae09",
            "e61773505a6640ec8bbc6a4713d21634",
            "2712074b799d45d08645a72e069b38b6"
          ]
        },
        "outputId": "fd344923-3984-46e9-e130-35c8a1c9f460"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/507 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e23eb79e4164c3e8255377c63c148f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/129M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87a0c90d741a49028a60d3c80be24091"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertModel: ['predictions.dense.weight', 'predictions.decoder.weight', 'predictions.dense.bias', 'sop_classifier.classifier.bias', 'predictions.bias', 'sop_classifier.classifier.weight', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.bias']\n",
            "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/5.38M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "103e4f9ffc914a81919ccb648cb202d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/21 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c19075abef54e8c87ad89fa1f4765e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# Load Indic Multilingual embeddings \n",
        "tp = TopicModelDataPreparation('ai4bharat/indic-bert')\n",
        "\n",
        "# Building training dataset\n",
        "training_dataset = tp.fit(text_for_contextual=unpreprocessed_corpus, text_for_bow=preprocessed_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8fmUu7dz_btU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65d096dc-5723-46ed-96e0-bba3b8acf5ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: [100/100]\t Seen Samples: [400300/400300]\tTrain Loss: 296.6654189045716\tTime: 0:00:00.837908: : 100it [01:22,  1.21it/s]\n",
            "Sampling: [30/30]: : 30it [00:22,  1.32it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/contextualized_topic_models/models/ctm.py:475: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
            "  Warning)\n",
            "Epoch: [100/100]\t Seen Samples: [400300/400300]\tTrain Loss: 303.732471642362\tTime: 0:00:00.860216: : 100it [01:24,  1.18it/s]\n",
            "Sampling: [30/30]: : 30it [00:23,  1.28it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/contextualized_topic_models/models/ctm.py:475: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
            "  Warning)\n"
          ]
        }
      ],
      "source": [
        "# Train over 100 epochs\n",
        "\n",
        "### HINDI : 25 TOPICS ###\n",
        "z_ctm_25_HI = ZeroShotTM(bow_size=len(tp.vocab), n_components = 25, contextual_size=768, num_epochs=100)\n",
        "\n",
        "z_ctm_25_HI.fit(training_dataset, n_samples = 30) # run the model\n",
        "z_ctm_25_HI.save(\"./\") # save the model\n",
        "\n",
        "### HINDI : 50 TOPICS ###\n",
        "z_ctm_50_HI = ZeroShotTM(bow_size=len(tp.vocab), n_components = 50, contextual_size=768, num_epochs=100)\n",
        "\n",
        "z_ctm_50_HI.fit(training_dataset, n_samples = 30) # run the model\n",
        "z_ctm_50_HI.save(\"./\") # save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "aYjDfidEcwOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "117f5b96-5f41-4fa3-e0c0-624aa9389203"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ठक', 'सम', 'रगत', 'सच', 'तर'],\n",
              " ['मह', 'रपत', 'सदस', 'गत', 'आपक'],\n",
              " ['उपसम', 'एफडब', 'एएनआर', 'गइ', 'आधर'],\n",
              " ['पन', 'एमओय', 'सहय', 'हस', 'षत']]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# See topic predictions per speech doc\n",
        "z_ctm_25_HI.get_topic_lists(5)[:4]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See topic predictions per speech doc\n",
        "z_ctm_50_HI.get_topic_lists(5)[:4]"
      ],
      "metadata": {
        "id": "d-ejLxGsnw5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a352c8a6-3925-48b7-86a1-dc0ddd7b809c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['लय', 'शन', 'हस', 'ऑफ', 'एमओय'],\n",
              " ['उन', 'अवसर', 'अभ', 'कल', 'जय'],\n",
              " ['यद', 'अगर', 'बत', 'इतन', 'ऐस'],\n",
              " ['इसर', 'उपग', 'पण', 'सफल', 'ईएमय']]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get NPMI Coherence\n",
        "from contextualized_topic_models.evaluation.measures import CoherenceNPMI\n",
        "texts = [doc.split() for doc in preprocessed_documents] # load text for NPMI\n",
        "\n",
        "### 25 TOPICS ###\n",
        "npmi_HI = CoherenceNPMI(texts=texts, topics=z_ctm_25_HI.get_topic_lists(25))\n",
        "print(npmi_HI.score())\n",
        "\n",
        "### 50 TOPICS ###\n",
        "npmi_50_HI = CoherenceNPMI(texts=texts, topics=z_ctm_50_HI.get_topic_lists(50))\n",
        "print(npmi_50_HI.score())\n",
        "\n",
        "# Store NPMI scores\n",
        "zeroshotNPMI_HI = [npmi_HI.score(), npmi_50_HI.score()]"
      ],
      "metadata": {
        "id": "uwYx_kW3oLun",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851b2b93-623f-4a54-9d91-996f2396e924"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.3133134617646065\n",
            "-0.31060041527417853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**English-Based ZeroshotTM**\n",
        "\n",
        "*Preprocessing*\n",
        "\n",
        "Why do we use the preprocessed text here? We need text without punctuation to build the bag of word. Also, we might want only to have the most frequent words inside the BoW. Too many words might not help."
      ],
      "metadata": {
        "id": "yJOkb0WAi617"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ENGLISH ###\n",
        "LANG_SELECTED = 'en'\n",
        "\n",
        "# We select 500 tokens per speech\n",
        "NUM_TOKENS = 500\n",
        "\n",
        "# Download English Stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Run preprocessing script\n",
        "documents = [line[:NUM_TOKENS].strip() for line in train_speeches[LANG_SELECTED]]\n",
        "\n",
        "import nltk\n",
        "nltk.download('words')\n",
        "# preprocessed_documents\n",
        "words = set(nltk.corpus.words.words())\n",
        "\n",
        "documents = [\"\".join([word for word in doc if word.lower() in words or not word.isalpha()]) for doc in documents]\n",
        "\n",
        "sp = WhiteSpacePreprocessing(documents, stopwords_language='english')\n",
        "preprocessed_documents, unpreprocessed_corpus, vocab = sp.preprocess()\n",
        "\n",
        "# Ensure same length for preprocessed and unpreprocessed\n",
        "print(len(preprocessed_documents), len(unpreprocessed_corpus))"
      ],
      "metadata": {
        "id": "0gQ4SObQLMin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ae08ad0-b02d-4d22-e0ff-d819a4f92f9c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/wordlist.py:28: ResourceWarning: unclosed file <_io.BufferedReader name='/root/nltk_data/corpora/words/en'>\n",
            "  return concat([self.open(f).read() for f in fileids])\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/wordlist.py:28: ResourceWarning: unclosed file <_io.BufferedReader name='/root/nltk_data/corpora/words/en-basic'>\n",
            "  return concat([self.open(f).read() for f in fileids])\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/wordlist.py:28: ResourceWarning: unclosed file <_io.BufferedReader name='/root/nltk_data/corpora/stopwords/english'>\n",
            "  return concat([self.open(f).read() for f in fileids])\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.7/dist-packages/contextualized_topic_models/utils/preprocessing.py:24: UserWarning: WhiteSpacePreprocessing is deprecated and will be removed in future versions.Use WhiteSpacePreprocessingStopwords.\n",
            "  warnings.warn(\"WhiteSpacePreprocessing is deprecated and will be removed in future versions.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4219 4219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't discard the non-preprocessed english texts, because we are going to use them as input for obtaining the **contextualized** document representations. We will now pass our files with preprocess and unpreprocessed data to our TopicModelDataPreparation object. This object takes care of creating the bag of words and obtains the contextualized BERT representations of documents. This operation allows us to create our training dataset.\n",
        "\n",
        "Note: Here we use the contextualized model \"ai4bharat/indic-bert\", because we need a multilingual model for indic languages for performing cross-lingual predictions later.\n",
        "\n"
      ],
      "metadata": {
        "id": "H904cm64wssn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building training dataset\n",
        "tp = TopicModelDataPreparation(\"ai4bharat/indic-bert\")\n",
        "en_training = tp.fit(text_for_contextual=unpreprocessed_corpus, text_for_bow=preprocessed_documents)"
      ],
      "metadata": {
        "id": "Uj-7NMBgN2oW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155,
          "referenced_widgets": [
            "506f57cad5d54e7387c9ffcf4dd0540a",
            "39fdd0608ded46efac9aa5d47adabbe9",
            "463731ab99e742499c2d6778445b8502",
            "8a95e2c364434aa29199787310da4213",
            "d8167fa2b1c94e6e932925cd25d62369",
            "ead59d73f4a549719407dbaf57189e2d",
            "e051a17cb3ea4157bf5ddc7e150c28c0",
            "fda3699f6dbc4b38b8baf20c26994071",
            "104a4429b90949f7a812242174c8e274",
            "ad805e7a622346ba9973f59293c1ac1d",
            "993930b9455f4efaa440dd65ac147093"
          ]
        },
        "outputId": "f693a382-3266-4478-f7aa-72b52625cdd8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertModel: ['predictions.dense.weight', 'predictions.decoder.weight', 'predictions.dense.bias', 'sop_classifier.classifier.bias', 'predictions.bias', 'sop_classifier.classifier.weight', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.bias']\n",
            "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/22 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "506f57cad5d54e7387c9ffcf4dd0540a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Training ZeroshotTM*"
      ],
      "metadata": {
        "id": "WLv6u6EklqNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train over 100 epochs\n",
        "\n",
        "### ENGLISH : 25 TOPICS ###\n",
        "z_ctm_25_EN = ZeroShotTM(bow_size=len(tp.vocab), n_components = 25, contextual_size=768, num_epochs=100)\n",
        "z_ctm_25_EN.fit(en_training, n_samples=30) # run the model\n",
        "z_ctm_25_EN.save(\"./\") # save the model\n",
        "\n",
        "### ENGLISH : 50 TOPICS ###\n",
        "z_ctm_50_EN = ZeroShotTM(bow_size=len(tp.vocab), n_components = 50, contextual_size=768, num_epochs=100)\n",
        "z_ctm_50_EN.fit(en_training, n_samples=30) # run the model\n",
        "z_ctm_50_EN.save(\"./\") # save the model"
      ],
      "metadata": {
        "id": "uYP1dTKrOFGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ddb61d7-5714-49b8-8b8f-ec9aaa466774"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: [100/100]\t Seen Samples: [421900/421900]\tTrain Loss: 236.97698724334853\tTime: 0:00:00.867364: : 100it [01:28,  1.13it/s]\n",
            "Sampling: [30/30]: : 30it [00:24,  1.25it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/contextualized_topic_models/models/ctm.py:475: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
            "  Warning)\n",
            "Epoch: [100/100]\t Seen Samples: [421900/421900]\tTrain Loss: 243.87289642095283\tTime: 0:00:00.869962: : 100it [01:28,  1.13it/s]\n",
            "Sampling: [30/30]: : 30it [00:24,  1.20it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/contextualized_topic_models/models/ctm.py:475: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n",
            "  Warning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See topic predictions per speech doc\n",
        "z_ctm_25_EN.get_topic_lists(5)[:4]"
      ],
      "metadata": {
        "id": "mgZAySpvOy4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "306b03ca-041c-4aef-da09-ca47267fed6a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['nuclear', 'ble', 'cancer', '20th', 'certificates'],\n",
              " ['said', 'today', 'delhi', 'new', 'addressed'],\n",
              " ['ble', 'cancer', '20th', 'bimstec', 'undertaken'],\n",
              " ['day', 'congratulated', 'proud', 'scientists', 'winning']]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See topic predictions per speech doc\n",
        "z_ctm_50_EN.get_topic_lists(5)[:4]"
      ],
      "metadata": {
        "id": "u1aSe9afj3pN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1131423b-6cf4-4f88-85e0-7487fd3cc4cf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['lives', 'families', 'loss', 'bus', 'thoughts'],\n",
              " ['cabinet', 'chaired', 'union', 'approval', 'approved'],\n",
              " ['minister', 'assured', 'situation', 'arising', 'stock'],\n",
              " ['visit', 'india', 'president', 'bilateral', 'mr']]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get NPMI Coherence\n",
        "from contextualized_topic_models.evaluation.measures import CoherenceNPMI\n",
        "texts = [doc.split() for doc in preprocessed_documents] # load text for NPMI\n",
        "\n",
        "### 25 TOPICS ###-\n",
        "npmi_EN = CoherenceNPMI(texts=texts, topics=z_ctm_25_EN.get_topic_lists(25))\n",
        "print(npmi_EN.score())\n",
        "\n",
        "### 50 TOPICS ###\n",
        "npmi_50_EN = CoherenceNPMI(texts=texts, topics=z_ctm_50_EN.get_topic_lists(50))\n",
        "print(npmi_50_EN.score())\n",
        "\n",
        "# Store NPMI scores\n",
        "zeroshotNPMI_EN = [npmi_EN.score(), npmi_50_EN.score()]"
      ],
      "metadata": {
        "id": "XQrm1TQXogzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "563dd942-1f9c-45dc-cf7b-08c1054ee7d0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.07190399877114767\n",
            "0.09796218295846393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coherence Results"
      ],
      "metadata": {
        "id": "i9PnZD8oouRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SHOW RESULTS\n",
        "NPMI = {\"ZeroShotTM for Hindi\" : zeroshotNPMI_HI,\n",
        "        \"ZeroShotTM for English\" : zeroshotNPMI_EN}\n",
        "\n",
        "npmi = pd.DataFrame.from_dict(NPMI, orient='index')\n",
        "print(\"NPMI Coherences\")\n",
        "npmi.set_axis([\"t(25)\", \"t(50)\"], axis = 1)"
      ],
      "metadata": {
        "id": "-wLgjEMMowtT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "df64669e-6e6c-400c-8c8f-66d530ef3c0d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPMI Coherences\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           t(25)     t(50)\n",
              "ZeroShotTM for Hindi   -0.313313 -0.310600\n",
              "ZeroShotTM for English  0.071904  0.097962"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e018f3e-f95d-4a00-9b02-dc96d21a1762\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>t(25)</th>\n",
              "      <th>t(50)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ZeroShotTM for Hindi</th>\n",
              "      <td>-0.313313</td>\n",
              "      <td>-0.310600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ZeroShotTM for English</th>\n",
              "      <td>0.071904</td>\n",
              "      <td>0.097962</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e018f3e-f95d-4a00-9b02-dc96d21a1762')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e018f3e-f95d-4a00-9b02-dc96d21a1762 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e018f3e-f95d-4a00-9b02-dc96d21a1762');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID4xeEywiyE1"
      },
      "source": [
        "# Predictions and Evaluation\n",
        "###**Unseen Multilingual  Corpora Predictions**\n",
        "\n",
        "*Languages*\n",
        "\n",
        "* Assamese - as\n",
        "* Bengali - bn\n",
        "* English - en\n",
        "* Gujarati - gu\n",
        "* Hindi - hi\n",
        "* Kannada - kn\n",
        "* Malayalam - ml\n",
        "* Marathi - mr\n",
        "* Oriya - or\n",
        "* Punjabi - pa\n",
        "* Tamil - ta\n",
        "* Telugu - te"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcyhlPNu3CiQ"
      },
      "outputs": [],
      "source": [
        "# Convert test files into test datasets\n",
        "as_testset = tp.transform(parallel_speeches['as'])\n",
        "bn_testset = tp.transform(parallel_speeches['bn'])\n",
        "en_testset = tp.transform(parallel_speeches['en'])\n",
        "gu_testset = tp.transform(parallel_speeches['gu'])\n",
        "hi_testset = tp.transform(parallel_speeches['hi'])\n",
        "kn_testset = tp.transform(parallel_speeches['kn'])\n",
        "ml_testset = tp.transform(parallel_speeches['ml'])\n",
        "mr_testset = tp.transform(parallel_speeches['mr'])\n",
        "or_testset = tp.transform(parallel_speeches['or'])\n",
        "pa_testset = tp.transform(parallel_speeches['pa'])\n",
        "ta_testset = tp.transform(parallel_speeches['ta'])\n",
        "te_testset = tp.transform(parallel_speeches['te'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Topic Predictions**\n",
        "\n",
        "*Hindi*"
      ],
      "metadata": {
        "id": "Vq0rRIiuo6Qx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "gy-tDYkpcDcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f516c76-cef5-4fff-c6fa-d61d2d283583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sampling: [100/100]: : 100it [00:40,  2.46it/s]\n",
            "Sampling: [100/100]: : 100it [00:40,  2.44it/s]\n",
            "Sampling: [100/100]: : 100it [00:41,  2.42it/s]\n",
            "Sampling: [100/100]: : 100it [00:41,  2.39it/s]\n",
            "Sampling: [100/100]: : 100it [00:42,  2.36it/s]\n",
            "Sampling: [100/100]: : 100it [00:43,  2.30it/s]\n",
            "Sampling: [100/100]: : 100it [00:43,  2.28it/s]\n",
            "Sampling: [100/100]: : 100it [00:44,  2.26it/s]\n",
            "Sampling: [100/100]: : 100it [00:45,  2.18it/s]\n",
            "Sampling: [100/100]: : 100it [00:45,  2.18it/s]\n",
            "Sampling: [100/100]: : 100it [00:45,  2.19it/s]\n",
            "Sampling: [100/100]: : 100it [00:46,  2.16it/s]\n"
          ]
        }
      ],
      "source": [
        "### HINDI : 25 TOPIC PREDICTIONS ### \n",
        "as_topics_predictions = z_ctm_25_HI.get_thetas(as_testset, n_samples=100) # get all the topic predictions\n",
        "bn_topics_predictions = z_ctm_25_HI.get_thetas(bn_testset, n_samples=100) # get all the topic predictions\n",
        "en_topics_predictions = z_ctm_25_HI.get_thetas(en_testset, n_samples=100) # get all the topic predictions\n",
        "gu_topics_predictions = z_ctm_25_HI.get_thetas(gu_testset, n_samples=100) # get all the topic predictions\n",
        "hi_topics_predictions = z_ctm_25_HI.get_thetas(hi_testset, n_samples=100) # get all the topic predictions\n",
        "kn_topics_predictions = z_ctm_25_HI.get_thetas(kn_testset, n_samples=100) # get all the topic predictions\n",
        "ml_topics_predictions = z_ctm_25_HI.get_thetas(ml_testset, n_samples=100) # get all the topic predictions\n",
        "mr_topics_predictions = z_ctm_25_HI.get_thetas(mr_testset, n_samples=100) # get all the topic predictions\n",
        "or_topics_predictions = z_ctm_25_HI.get_thetas(or_testset, n_samples=100) # get all the topic predictions\n",
        "pa_topics_predictions = z_ctm_25_HI.get_thetas(pa_testset, n_samples=100) # get all the topic predictions\n",
        "ta_topics_predictions = z_ctm_25_HI.get_thetas(ta_testset, n_samples=100) # get all the topic predictions\n",
        "te_topics_predictions = z_ctm_25_HI.get_thetas(te_testset, n_samples=100) # get all the topic predictions\n",
        "\n",
        "topics_25_HI = {'as': as_topics_predictions, 'bn': bn_topics_predictions, \n",
        "             'en': en_topics_predictions, 'gu': gu_topics_predictions,\n",
        "             'hi': hi_topics_predictions, 'kn': kn_topics_predictions,\n",
        "             'ml': ml_topics_predictions, 'mr': mr_topics_predictions,\n",
        "             'or': or_topics_predictions, 'pa': pa_topics_predictions,\n",
        "             'ta': ta_topics_predictions, 'te': te_topics_predictions}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "d5ZFFpd43v6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20779fdf-1d36-4e7f-8760-a3c1c3fee734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sampling: [100/100]: : 100it [00:47,  2.11it/s]\n",
            "Sampling: [100/100]: : 100it [00:47,  2.09it/s]\n",
            "Sampling: [100/100]: : 100it [00:48,  2.07it/s]\n",
            "Sampling: [100/100]: : 100it [00:49,  2.03it/s]\n",
            "Sampling: [100/100]: : 100it [00:49,  2.03it/s]\n",
            "Sampling: [100/100]: : 100it [00:49,  2.01it/s]\n",
            "Sampling: [100/100]: : 100it [00:50,  1.97it/s]\n",
            "Sampling: [100/100]: : 100it [00:51,  1.95it/s]\n",
            "Sampling: [100/100]: : 100it [00:51,  1.92it/s]\n",
            "Sampling: [100/100]: : 100it [00:53,  1.88it/s]\n",
            "Sampling: [100/100]: : 100it [00:53,  1.86it/s]\n",
            "Sampling: [100/100]: : 100it [00:54,  1.83it/s]\n"
          ]
        }
      ],
      "source": [
        "### HINDI : 50 TOPIC PREDICTIONS ### \n",
        "as_topics_predictions = z_ctm_50_HI.get_thetas(as_testset, n_samples=100) # get all the topic predictions\n",
        "bn_topics_predictions = z_ctm_50_HI.get_thetas(bn_testset, n_samples=100) # get all the topic predictions\n",
        "en_topics_predictions = z_ctm_50_HI.get_thetas(en_testset, n_samples=100) # get all the topic predictions\n",
        "gu_topics_predictions = z_ctm_50_HI.get_thetas(gu_testset, n_samples=100) # get all the topic predictions\n",
        "hi_topics_predictions = z_ctm_50_HI.get_thetas(hi_testset, n_samples=100) # get all the topic predictions\n",
        "kn_topics_predictions = z_ctm_50_HI.get_thetas(kn_testset, n_samples=100) # get all the topic predictions\n",
        "ml_topics_predictions = z_ctm_50_HI.get_thetas(ml_testset, n_samples=100) # get all the topic predictions\n",
        "mr_topics_predictions = z_ctm_50_HI.get_thetas(mr_testset, n_samples=100) # get all the topic predictions\n",
        "or_topics_predictions = z_ctm_50_HI.get_thetas(or_testset, n_samples=100) # get all the topic predictions\n",
        "pa_topics_predictions = z_ctm_50_HI.get_thetas(pa_testset, n_samples=100) # get all the topic predictions\n",
        "ta_topics_predictions = z_ctm_50_HI.get_thetas(ta_testset, n_samples=100) # get all the topic predictions\n",
        "te_topics_predictions = z_ctm_50_HI.get_thetas(te_testset, n_samples=100) # get all the topic predictions\n",
        "\n",
        "topics_50_HI = {'as': as_topics_predictions, 'bn': bn_topics_predictions, \n",
        "             'en': en_topics_predictions, 'gu': gu_topics_predictions,\n",
        "             'hi': hi_topics_predictions, 'kn': kn_topics_predictions,\n",
        "             'ml': ml_topics_predictions, 'mr': mr_topics_predictions,\n",
        "             'or': or_topics_predictions, 'pa': pa_topics_predictions,\n",
        "             'ta': ta_topics_predictions, 'te': te_topics_predictions}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*English*"
      ],
      "metadata": {
        "id": "t6Jom4sqpHyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ENGLISH : 25 TOPIC PREDICTIONS ### \n",
        "as_topics_predictions = z_ctm_25_EN.get_thetas(as_testset, n_samples=100) # get all the topic predictions\n",
        "bn_topics_predictions = z_ctm_25_EN.get_thetas(bn_testset, n_samples=100) # get all the topic predictions\n",
        "en_topics_predictions = z_ctm_25_EN.get_thetas(en_testset, n_samples=100) # get all the topic predictions\n",
        "gu_topics_predictions = z_ctm_25_EN.get_thetas(gu_testset, n_samples=100) # get all the topic predictions\n",
        "hi_topics_predictions = z_ctm_25_EN.get_thetas(hi_testset, n_samples=100) # get all the topic predictions\n",
        "kn_topics_predictions = z_ctm_25_EN.get_thetas(kn_testset, n_samples=100) # get all the topic predictions\n",
        "ml_topics_predictions = z_ctm_25_EN.get_thetas(ml_testset, n_samples=100) # get all the topic predictions\n",
        "mr_topics_predictions = z_ctm_25_EN.get_thetas(mr_testset, n_samples=100) # get all the topic predictions\n",
        "or_topics_predictions = z_ctm_25_EN.get_thetas(or_testset, n_samples=100) # get all the topic predictions\n",
        "pa_topics_predictions = z_ctm_25_EN.get_thetas(pa_testset, n_samples=100) # get all the topic predictions\n",
        "ta_topics_predictions = z_ctm_25_EN.get_thetas(ta_testset, n_samples=100) # get all the topic predictions\n",
        "te_topics_predictions = z_ctm_25_EN.get_thetas(te_testset, n_samples=100) # get all the topic predictions\n",
        "\n",
        "topics_25_EN = {'as': as_topics_predictions, 'bn': bn_topics_predictions, \n",
        "             'en': en_topics_predictions, 'gu': gu_topics_predictions,\n",
        "             'hi': hi_topics_predictions, 'kn': kn_topics_predictions,\n",
        "             'ml': ml_topics_predictions, 'mr': mr_topics_predictions,\n",
        "             'or': or_topics_predictions, 'pa': pa_topics_predictions,\n",
        "             'ta': ta_topics_predictions, 'te': te_topics_predictions}"
      ],
      "metadata": {
        "id": "8Abhs52LpLt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a109a2-85ac-41f1-ca77-32f2c9c13b9a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sampling: [100/100]: : 100it [00:54,  1.83it/s]\n",
            "Sampling: [100/100]: : 100it [00:55,  1.79it/s]\n",
            "Sampling: [100/100]: : 100it [00:56,  1.77it/s]\n",
            "Sampling: [100/100]: : 100it [00:57,  1.74it/s]\n",
            "Sampling: [100/100]: : 100it [00:57,  1.73it/s]\n",
            "Sampling: [100/100]: : 100it [00:57,  1.73it/s]\n",
            "Sampling: [100/100]: : 100it [00:58,  1.70it/s]\n",
            "Sampling: [100/100]: : 100it [00:59,  1.68it/s]\n",
            "Sampling: [100/100]: : 100it [01:00,  1.66it/s]\n",
            "Sampling: [100/100]: : 100it [01:00,  1.65it/s]\n",
            "Sampling: [100/100]: : 100it [01:00,  1.64it/s]\n",
            "Sampling: [100/100]: : 100it [01:01,  1.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### ENGLISH : 50 TOPIC PREDICTIONS ### \n",
        "as_topics_predictions = z_ctm_50_EN.get_thetas(as_testset, n_samples=100) # get all the topic predictions\n",
        "bn_topics_predictions = z_ctm_50_EN.get_thetas(bn_testset, n_samples=100) # get all the topic predictions\n",
        "en_topics_predictions = z_ctm_50_EN.get_thetas(en_testset, n_samples=100) # get all the topic predictions\n",
        "gu_topics_predictions = z_ctm_50_EN.get_thetas(gu_testset, n_samples=100) # get all the topic predictions\n",
        "hi_topics_predictions = z_ctm_50_EN.get_thetas(hi_testset, n_samples=100) # get all the topic predictions\n",
        "kn_topics_predictions = z_ctm_50_EN.get_thetas(kn_testset, n_samples=100) # get all the topic predictions\n",
        "ml_topics_predictions = z_ctm_50_EN.get_thetas(ml_testset, n_samples=100) # get all the topic predictions\n",
        "mr_topics_predictions = z_ctm_50_EN.get_thetas(mr_testset, n_samples=100) # get all the topic predictions\n",
        "or_topics_predictions = z_ctm_50_EN.get_thetas(or_testset, n_samples=100) # get all the topic predictions\n",
        "pa_topics_predictions = z_ctm_50_EN.get_thetas(pa_testset, n_samples=100) # get all the topic predictions\n",
        "ta_topics_predictions = z_ctm_50_EN.get_thetas(ta_testset, n_samples=100) # get all the topic predictions\n",
        "te_topics_predictions = z_ctm_50_EN.get_thetas(te_testset, n_samples=100) # get all the topic predictions\n",
        "\n",
        "topics_50_EN = {'as': as_topics_predictions, 'bn': bn_topics_predictions, \n",
        "             'en': en_topics_predictions, 'gu': gu_topics_predictions,\n",
        "             'hi': hi_topics_predictions, 'kn': kn_topics_predictions,\n",
        "             'ml': ml_topics_predictions, 'mr': mr_topics_predictions,\n",
        "             'or': or_topics_predictions, 'pa': pa_topics_predictions,\n",
        "             'ta': ta_topics_predictions, 'te': te_topics_predictions}"
      ],
      "metadata": {
        "id": "QnJLxNixpL9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1220e834-0b4d-4f2e-833c-af09d646a73f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sampling: [100/100]: : 100it [01:03,  1.57it/s]\n",
            "Sampling: [100/100]: : 100it [01:05,  1.53it/s]\n",
            "Sampling: [100/100]: : 100it [01:05,  1.54it/s]\n",
            "Sampling: [100/100]: : 100it [01:04,  1.56it/s]\n",
            "Sampling: [100/100]: : 100it [01:05,  1.53it/s]\n",
            "Sampling: [100/100]: : 100it [01:05,  1.52it/s]\n",
            "Sampling: [100/100]: : 100it [01:06,  1.50it/s]\n",
            "Sampling: [100/100]: : 100it [01:07,  1.49it/s]\n",
            "Sampling: [100/100]: : 100it [01:07,  1.47it/s]\n",
            "Sampling: [100/100]: : 100it [01:08,  1.46it/s]\n",
            "Sampling: [100/100]: : 100it [01:09,  1.45it/s]\n",
            "Sampling: [100/100]: : 100it [01:10,  1.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EyO4qpXm4Nj"
      },
      "source": [
        "### **Quantitative Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "PUHdC6ztmzr5"
      },
      "outputs": [],
      "source": [
        "# Import metrics\n",
        "from contextualized_topic_models.evaluation.measures import Matches, KLDivergence, CentroidDistance\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJvWmhANeWea"
      },
      "source": [
        "1. **Matches**\n",
        "\n",
        "> Matches is the % of times the predicted topic for the non-English test document is the same as for the respective test document in English. The higher the scores, the better."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Hindi*"
      ],
      "metadata": {
        "id": "X0BmiGNcrVKD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "aF2GPx1_5Mal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf41704-b2df-402e-d5e5-facef1cac10f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'as': 0.2525,\n",
              " 'bn': 0.30875,\n",
              " 'en': 0.0375,\n",
              " 'gu': 0.4775,\n",
              " 'kn': 0.24125,\n",
              " 'ml': 0.09125,\n",
              " 'mr': 0.38125,\n",
              " 'or': 0.31875,\n",
              " 'pa': 0.47125,\n",
              " 'ta': 0.09625,\n",
              " 'te': 0.14375}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# HINDI : Matches for 25 topics\n",
        "hi_as_matches = Matches(topics_25_HI['hi'], topics_25_HI['as'])\n",
        "hi_bn_matches = Matches(topics_25_HI['hi'], topics_25_HI['bn'])\n",
        "hi_en_matches = Matches(topics_25_HI['hi'], topics_25_HI['en'])\n",
        "hi_gu_matches = Matches(topics_25_HI['hi'], topics_25_HI['gu'])\n",
        "hi_kn_matches = Matches(topics_25_HI['hi'], topics_25_HI['kn'])\n",
        "hi_ml_matches = Matches(topics_25_HI['hi'], topics_25_HI['ml'])\n",
        "hi_mr_matches = Matches(topics_25_HI['hi'], topics_25_HI['mr'])\n",
        "hi_or_matches = Matches(topics_25_HI['hi'], topics_25_HI['or'])\n",
        "hi_pa_matches = Matches(topics_25_HI['hi'], topics_25_HI['pa'])\n",
        "hi_ta_matches = Matches(topics_25_HI['hi'], topics_25_HI['ta'])\n",
        "hi_te_matches = Matches(topics_25_HI['hi'], topics_25_HI['te'])\n",
        "\n",
        "\n",
        "matches_25_HI = {'as': hi_as_matches.score(), 'bn': hi_bn_matches.score(), \n",
        "             'en': hi_en_matches.score(), 'gu': hi_gu_matches.score(),\n",
        "             'kn': hi_kn_matches.score(),\n",
        "             'ml': hi_ml_matches.score(), 'mr': hi_mr_matches.score(),\n",
        "             'or': hi_or_matches.score(), 'pa': hi_pa_matches.score(),\n",
        "             'ta': hi_ta_matches.score(), 'te': hi_te_matches.score()}\n",
        "matches_25_HI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "WLw8Xkt5dElD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068c9e90-e8a3-4270-e8e9-0a60a80ae0cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'as': 0.10625,\n",
              " 'bn': 0.15,\n",
              " 'en': 0.04,\n",
              " 'gu': 0.28875,\n",
              " 'kn': 0.12875,\n",
              " 'ml': 0.05625,\n",
              " 'mr': 0.23,\n",
              " 'or': 0.23375,\n",
              " 'pa': 0.34625,\n",
              " 'ta': 0.06125,\n",
              " 'te': 0.06625}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# HINDI : Matches for 50 topics\n",
        "hi_as_matches = Matches(topics_50_HI['hi'], topics_50_HI['as'])\n",
        "hi_bn_matches = Matches(topics_50_HI['hi'], topics_50_HI['bn'])\n",
        "hi_en_matches = Matches(topics_50_HI['hi'], topics_50_HI['en'])\n",
        "hi_gu_matches = Matches(topics_50_HI['hi'], topics_50_HI['gu'])\n",
        "hi_kn_matches = Matches(topics_50_HI['hi'], topics_50_HI['kn'])\n",
        "hi_ml_matches = Matches(topics_50_HI['hi'], topics_50_HI['ml'])\n",
        "hi_mr_matches = Matches(topics_50_HI['hi'], topics_50_HI['mr'])\n",
        "hi_or_matches = Matches(topics_50_HI['hi'], topics_50_HI['or'])\n",
        "hi_pa_matches = Matches(topics_50_HI['hi'], topics_50_HI['pa'])\n",
        "hi_ta_matches = Matches(topics_50_HI['hi'], topics_50_HI['ta'])\n",
        "hi_te_matches = Matches(topics_50_HI['hi'], topics_50_HI['te'])\n",
        "\n",
        "\n",
        "matches_50_HI = {'as': hi_as_matches.score(), 'bn': hi_bn_matches.score(), \n",
        "             'en': hi_en_matches.score(), 'gu': hi_gu_matches.score(),\n",
        "             'kn': hi_kn_matches.score(),\n",
        "             'ml': hi_ml_matches.score(), 'mr': hi_mr_matches.score(),\n",
        "             'or': hi_or_matches.score(), 'pa': hi_pa_matches.score(),\n",
        "             'ta': hi_ta_matches.score(), 'te': hi_te_matches.score()}\n",
        "matches_50_HI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*English*"
      ],
      "metadata": {
        "id": "o862P3oerW-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ENGLISH : Matches for 25 topics\n",
        "en_as_matches = Matches(topics_25_EN['en'], topics_25_EN['as'])\n",
        "en_bn_matches = Matches(topics_25_EN['en'], topics_25_EN['bn'])\n",
        "en_hi_matches = Matches(topics_25_EN['en'], topics_25_EN['hi'])\n",
        "en_gu_matches = Matches(topics_25_EN['en'], topics_25_EN['gu'])\n",
        "en_kn_matches = Matches(topics_25_EN['en'], topics_25_EN['kn'])\n",
        "en_ml_matches = Matches(topics_25_EN['en'], topics_25_EN['ml'])\n",
        "en_mr_matches = Matches(topics_25_EN['en'], topics_25_EN['mr'])\n",
        "en_or_matches = Matches(topics_25_EN['en'], topics_25_EN['or'])\n",
        "en_pa_matches = Matches(topics_25_EN['en'], topics_25_EN['pa'])\n",
        "en_ta_matches = Matches(topics_25_EN['en'], topics_25_EN['ta'])\n",
        "en_te_matches = Matches(topics_25_EN['en'], topics_25_EN['te'])\n",
        "\n",
        "\n",
        "matches_25_EN = {'as': en_as_matches.score(), 'bn': en_bn_matches.score(), \n",
        "             'en': en_hi_matches.score(), 'gu': en_gu_matches.score(),\n",
        "             'kn': en_kn_matches.score(),\n",
        "             'ml': en_ml_matches.score(), 'mr': en_mr_matches.score(),\n",
        "             'or': en_or_matches.score(), 'pa': en_pa_matches.score(),\n",
        "             'ta': en_ta_matches.score(), 'te': en_te_matches.score()}\n",
        "matches_25_EN"
      ],
      "metadata": {
        "id": "0-D9lipprab7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a944027e-9d85-406b-db58-3e95dd9718e2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'as': 0.24,\n",
              " 'bn': 0.255,\n",
              " 'en': 0.37875,\n",
              " 'gu': 0.435,\n",
              " 'kn': 0.3025,\n",
              " 'ml': 0.1975,\n",
              " 'mr': 0.27125,\n",
              " 'or': 0.275,\n",
              " 'pa': 0.4375,\n",
              " 'ta': 0.1575,\n",
              " 'te': 0.17875}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ENGLISH : Matches for 50 topics\n",
        "en_as_matches = Matches(topics_50_EN['en'], topics_50_EN['as'])\n",
        "en_bn_matches = Matches(topics_50_EN['en'], topics_50_EN['bn'])\n",
        "en_en_matches = Matches(topics_50_EN['en'], topics_50_EN['hi'])\n",
        "en_gu_matches = Matches(topics_50_EN['en'], topics_50_EN['gu'])\n",
        "en_kn_matches = Matches(topics_50_EN['en'], topics_50_EN['kn'])\n",
        "en_ml_matches = Matches(topics_50_EN['en'], topics_50_EN['ml'])\n",
        "en_mr_matches = Matches(topics_50_EN['en'], topics_50_EN['mr'])\n",
        "en_or_matches = Matches(topics_50_EN['en'], topics_50_EN['or'])\n",
        "en_pa_matches = Matches(topics_50_EN['en'], topics_50_EN['pa'])\n",
        "en_ta_matches = Matches(topics_50_EN['en'], topics_50_EN['ta'])\n",
        "en_te_matches = Matches(topics_50_EN['en'], topics_50_EN['te'])\n",
        "\n",
        "\n",
        "matches_50_EN = {'as': en_as_matches.score(), 'bn': en_bn_matches.score(), \n",
        "             'en': en_hi_matches.score(), 'gu': en_gu_matches.score(),\n",
        "             'kn': en_kn_matches.score(),\n",
        "             'ml': en_ml_matches.score(), 'mr': en_mr_matches.score(),\n",
        "             'or': en_or_matches.score(), 'pa': en_pa_matches.score(),\n",
        "             'ta': en_ta_matches.score(), 'te': en_te_matches.score()}\n",
        "matches_50_EN"
      ],
      "metadata": {
        "id": "3REUgwm-ryeG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cbbe368-1503-4ef7-b9bf-aa7f982d1e42"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'as': 0.1475,\n",
              " 'bn': 0.1625,\n",
              " 'en': 0.37875,\n",
              " 'gu': 0.28875,\n",
              " 'kn': 0.1925,\n",
              " 'ml': 0.09125,\n",
              " 'mr': 0.1875,\n",
              " 'or': 0.19,\n",
              " 'pa': 0.34,\n",
              " 'ta': 0.0675,\n",
              " 'te': 0.115}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PysLdKoyZ-fS"
      },
      "source": [
        "2. **Distributional Similarity**\n",
        "> Compute the KL divergence between the predicted topic distribution on the test document and the same test document in English. Lower scores are better, indicating that the distributions do not differ by much."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Hindi*"
      ],
      "metadata": {
        "id": "0qDKyNdesFO_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "nc8TYrOCnUt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e1ed61b-5021-45ed-adad-296c4ef6265f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'as': 0.6725276656788808,\n",
              " 'bn': 0.8627264330569175,\n",
              " 'en': 7.858056221060294,\n",
              " 'gu': 0.3541341356827201,\n",
              " 'kn': 0.8892348424435308,\n",
              " 'ml': 1.5146623473210428,\n",
              " 'mr': 0.6220876620603729,\n",
              " 'or': 0.5582947561514637,\n",
              " 'pa': 0.36843128152525806,\n",
              " 'ta': 1.4094752864237194,\n",
              " 'te': 0.8195502205718874}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# HINDI : KL Divergence for 25 topics\n",
        "hi_as_kl = KLDivergence(topics_25_HI['hi'], topics_25_HI['as'])\n",
        "hi_bn_kl = KLDivergence(topics_25_HI['hi'], topics_25_HI['bn'])\n",
        "hi_en_kl = KLDivergence(topics_25_HI['hi'], topics_25_HI['en'])\n",
        "hi_gu_kl = KLDivergence(topics_25_HI['hi'], topics_25_HI['gu'])\n",
        "hi_kn_kl = KLDivergence(topics_25_HI['hi'], topics_25_HI['kn'])\n",
        "hi_ml_kl = KLDivergence(topics_25_HI['hi'], topics_25_HI['ml'])\n",
        "hi_mr_kl = KLDivergence(topics_25_HI['hi'], topics_25_HI['mr'])\n",
        "hi_or_kl = KLDivergence(topics_25_HI['hi'], topics_25_HI['or'])\n",
        "hi_pa_kl = KLDivergence(topics_25_HI['hi'], topics_25_HI['pa'])\n",
        "hi_ta_kl = KLDivergence(topics_25_HI['hi'], topics_25_HI['ta'])\n",
        "hi_te_kl = KLDivergence(topics_25_HI['hi'], topics_25_HI['te'])\n",
        "\n",
        "kl_divergence_25_HI = {'as': hi_as_kl.score(), 'bn': hi_bn_kl.score(), \n",
        "             'en': hi_en_kl.score(), 'gu': hi_gu_kl.score(),\n",
        "             'kn': hi_kn_kl.score(),\n",
        "             'ml': hi_ml_kl.score(), 'mr': hi_mr_kl.score(),\n",
        "             'or': hi_or_kl.score(), 'pa': hi_pa_kl.score(),\n",
        "             'ta': hi_ta_kl.score(), 'te': hi_te_kl.score()}\n",
        "\n",
        "kl_divergence_25_HI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "OztmlUHK5M8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b01dab44-c3a9-4bea-c70a-243d3733986d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'as': 0.6648448247811163,\n",
              " 'bn': 0.6682072268603605,\n",
              " 'en': 7.827630413179365,\n",
              " 'gu': 0.33799820575742406,\n",
              " 'kn': 0.7568196267095151,\n",
              " 'ml': 1.0196003953964474,\n",
              " 'mr': 0.5275078150363133,\n",
              " 'or': 0.45549437645320817,\n",
              " 'pa': 0.3046564891573344,\n",
              " 'ta': 1.0736741774066885,\n",
              " 'te': 0.9940683614519996}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# HINDI : KL Divergence for 50 topics\n",
        "hi_as_kl = KLDivergence(topics_50_HI['hi'], topics_50_HI['as'])\n",
        "hi_bn_kl = KLDivergence(topics_50_HI['hi'], topics_50_HI['bn'])\n",
        "hi_en_kl = KLDivergence(topics_50_HI['hi'], topics_50_HI['en'])\n",
        "hi_gu_kl = KLDivergence(topics_50_HI['hi'], topics_50_HI['gu'])\n",
        "hi_kn_kl = KLDivergence(topics_50_HI['hi'], topics_50_HI['kn'])\n",
        "hi_ml_kl = KLDivergence(topics_50_HI['hi'], topics_50_HI['ml'])\n",
        "hi_mr_kl = KLDivergence(topics_50_HI['hi'], topics_50_HI['mr'])\n",
        "hi_or_kl = KLDivergence(topics_50_HI['hi'], topics_50_HI['or'])\n",
        "hi_pa_kl = KLDivergence(topics_50_HI['hi'], topics_50_HI['pa'])\n",
        "hi_ta_kl = KLDivergence(topics_50_HI['hi'], topics_50_HI['ta'])\n",
        "hi_te_kl = KLDivergence(topics_50_HI['hi'], topics_50_HI['te'])\n",
        "\n",
        "kl_divergence_50_HI = {'as': hi_as_kl.score(), 'bn': hi_bn_kl.score(), \n",
        "             'en': hi_en_kl.score(), 'gu': hi_gu_kl.score(),\n",
        "             'kn': hi_kn_kl.score(),\n",
        "             'ml': hi_ml_kl.score(), 'mr': hi_mr_kl.score(),\n",
        "             'or': hi_or_kl.score(), 'pa': hi_pa_kl.score(),\n",
        "             'ta': hi_ta_kl.score(), 'te': hi_te_kl.score()}\n",
        "\n",
        "kl_divergence_50_HI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*English*"
      ],
      "metadata": {
        "id": "JyxUuP1bsG_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ENGLISH : KL Divergence for 25 topics\n",
        "en_as_kl = KLDivergence(topics_25_EN['en'], topics_25_EN['as'])\n",
        "en_bn_kl = KLDivergence(topics_25_EN['en'], topics_25_EN['bn'])\n",
        "en_hi_kl = KLDivergence(topics_25_EN['en'], topics_25_EN['hi'])\n",
        "en_gu_kl = KLDivergence(topics_25_EN['en'], topics_25_EN['gu'])\n",
        "en_kn_kl = KLDivergence(topics_25_EN['en'], topics_25_EN['kn'])\n",
        "en_ml_kl = KLDivergence(topics_25_EN['en'], topics_25_EN['ml'])\n",
        "en_mr_kl = KLDivergence(topics_25_EN['en'], topics_25_EN['mr'])\n",
        "en_or_kl = KLDivergence(topics_25_EN['en'], topics_25_EN['or'])\n",
        "en_pa_kl = KLDivergence(topics_25_EN['en'], topics_25_EN['pa'])\n",
        "en_ta_kl = KLDivergence(topics_25_EN['en'], topics_25_EN['ta'])\n",
        "en_te_kl = KLDivergence(topics_25_EN['en'], topics_25_EN['te'])\n",
        "\n",
        "kl_divergence_25_EN = {'as': en_as_kl.score(), 'bn': en_bn_kl.score(), \n",
        "             'hi': en_hi_kl.score(), 'gu': en_gu_kl.score(),\n",
        "             'kn': en_kn_kl.score(),\n",
        "             'ml': en_ml_kl.score(), 'mr': en_mr_kl.score(),\n",
        "             'or': en_or_kl.score(), 'pa': en_pa_kl.score(),\n",
        "             'ta': en_ta_kl.score(), 'te': en_te_kl.score()}\n",
        "\n",
        "kl_divergence_25_EN"
      ],
      "metadata": {
        "id": "ieStOUDKsJMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fab7df8-1eeb-4441-f410-55cfa311bbf8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'as': 0.4417607160995153,\n",
              " 'bn': 0.36924523223880285,\n",
              " 'gu': 0.24243747921365444,\n",
              " 'hi': 0.2729636354343089,\n",
              " 'kn': 0.35162599142604684,\n",
              " 'ml': 0.5285727255602641,\n",
              " 'mr': 0.3594530848440848,\n",
              " 'or': 0.3875130856447477,\n",
              " 'pa': 0.20496066719003037,\n",
              " 'ta': 0.5392350782809777,\n",
              " 'te': 0.5993194518956494}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ENGLISH : KL Divergence for 50 topics\n",
        "en_as_kl = KLDivergence(topics_50_EN['en'], topics_50_EN['as'])\n",
        "en_bn_kl = KLDivergence(topics_50_EN['en'], topics_50_EN['bn'])\n",
        "en_hi_kl = KLDivergence(topics_50_EN['en'], topics_50_EN['hi'])\n",
        "en_gu_kl = KLDivergence(topics_50_EN['en'], topics_50_EN['gu'])\n",
        "en_kn_kl = KLDivergence(topics_50_EN['en'], topics_50_EN['kn'])\n",
        "en_ml_kl = KLDivergence(topics_50_EN['en'], topics_50_EN['ml'])\n",
        "en_mr_kl = KLDivergence(topics_50_EN['en'], topics_50_EN['mr'])\n",
        "en_or_kl = KLDivergence(topics_50_EN['en'], topics_50_EN['or'])\n",
        "en_pa_kl = KLDivergence(topics_50_EN['en'], topics_50_EN['pa'])\n",
        "en_ta_kl = KLDivergence(topics_50_EN['en'], topics_50_EN['ta'])\n",
        "en_te_kl = KLDivergence(topics_50_EN['en'], topics_50_EN['te'])\n",
        "\n",
        "kl_divergence_50_EN = {'as': en_as_kl.score(), 'bn': en_bn_kl.score(), \n",
        "             'hi': en_hi_kl.score(), 'gu': en_gu_kl.score(),\n",
        "             'kn': en_kn_kl.score(),\n",
        "             'ml': en_ml_kl.score(), 'mr': en_mr_kl.score(),\n",
        "             'or': en_or_kl.score(), 'pa': en_pa_kl.score(),\n",
        "             'ta': en_ta_kl.score(), 'te': en_te_kl.score()}\n",
        "\n",
        "kl_divergence_50_EN"
      ],
      "metadata": {
        "id": "ierbd5Uws0T1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0661c6f2-2bc9-4817-fd92-dc9c44277c6e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'as': 0.54250369426347,\n",
              " 'bn': 0.5060315250027786,\n",
              " 'gu': 0.3452978266719059,\n",
              " 'hi': 0.33564429664393997,\n",
              " 'kn': 0.4874127049552386,\n",
              " 'ml': 0.7135579099614339,\n",
              " 'mr': 0.49344311940679936,\n",
              " 'or': 0.5106467010934378,\n",
              " 'pa': 0.2711361122159386,\n",
              " 'ta': 0.7307446922882802,\n",
              " 'te': 0.6829491978402412}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzpXFJ0wZ5-2"
      },
      "source": [
        "3. **Centroid Embeddings**\n",
        "> To also account for similar but not exactly equal topic predictions, we compute the centroid embeddings of the 5 words describing the predicted topic for both English and non-English documents. Then we compute the cosine similarity between those two centroids (CD)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "AbXgKs-u5NyD"
      },
      "outputs": [],
      "source": [
        "from gensim.corpora.dictionary import Dictionary\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.models import KeyedVectors\n",
        "import gensim.downloader as api\n",
        "from scipy.spatial.distance import cosine\n",
        "import abc\n",
        "import numpy as np\n",
        "\n",
        "class CD(CentroidDistance):\n",
        "    \"\"\"Override author's function to upgrade compatibility with Gensim 4.0.0.\n",
        "    See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4.\"\"\"\n",
        "\n",
        "    def get_centroid(self, word_list):\n",
        "        vector_list = []\n",
        "        for word in word_list:\n",
        "            if word in self.wv:   # changed from self.wv.vocab to self.wv as in Gensim 4.0.0\n",
        "                vector_list.append(self.wv.get_vector(word))\n",
        "        vec = sum(vector_list)\n",
        "        return vec / np.linalg.norm(vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Hindi*"
      ],
      "metadata": {
        "id": "2Hp8OuALtmOF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "CjnYIIng5MyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09af29a-52f5-4302-9231-b6b9c098951e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'as': nan,\n",
              " 'bn': nan,\n",
              " 'en': nan,\n",
              " 'gu': nan,\n",
              " 'kn': nan,\n",
              " 'ml': nan,\n",
              " 'mr': nan,\n",
              " 'or': nan,\n",
              " 'pa': nan,\n",
              " 'ta': nan,\n",
              " 'te': nan}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# HINDI : Centroid Embeddings for 25 topics\n",
        "cd_25_HI = {}\n",
        "\n",
        "for key in topics_25_HI.keys():\n",
        "  if key == 'hi':\n",
        "    continue\n",
        "  topic = topics_25_HI[key]\n",
        "  cd = CD(doc_distribution_original_language = topics_25_HI['hi'], \n",
        "          doc_distribution_unseen_language = topic, \n",
        "          topics = z_ctm_25_HI.get_topic_lists(25),\n",
        "          topk = 5)\n",
        "  \n",
        "  cd_25_HI[key] = cd.score()\n",
        "\n",
        "cd_25_HI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "WXRBx6VjW-5q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "4d19cf9e-8e1b-4c4c-9a08-2644643359b5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-a34ad3a74e9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mdoc_distribution_unseen_language\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_ctm_50_HI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_topic_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m           topk = 5)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mcd_50_HI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/contextualized_topic_models/evaluation/measures.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, doc_distribution_original_language, doc_distribution_unseen_language, topics, word2vec_path, binary, topk)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword2vec_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word2vec-google-news-300'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/downloader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, return_path)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/root/gensim-data/word2vec-google-news-300/__init__.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'word2vec-google-news-300'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"word2vec-google-news-300.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1629\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1630\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m         )\n\u001b[1;32m   1633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   1971\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m             _word2vec_read_binary(\n\u001b[0;32m-> 1973\u001b[0;31m                 \u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_chunk_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1974\u001b[0m             )\n\u001b[1;32m   1975\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_word2vec_read_binary\u001b[0;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size)\u001b[0m\n\u001b[1;32m   1863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mtot_processed_words\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1865\u001b[0;31m         \u001b[0mnew_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_chunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1866\u001b[0m         \u001b[0mchunk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1867\u001b[0m         processed_words, chunk = _add_bytes_to_kv(\n",
            "\u001b[0;32m/usr/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0muncompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# HINDI : Centroid Embeddings for 50 topics\n",
        "cd_50_HI = {}\n",
        "\n",
        "for key in topics_50_HI.keys():\n",
        "  if key == 'hi':\n",
        "    continue\n",
        "  topic = topics_50_HI[key]\n",
        "  cd = CD(doc_distribution_original_language = topics_50_HI['hi'], \n",
        "          doc_distribution_unseen_language = topic, \n",
        "          topics = z_ctm_50_HI.get_topic_lists(50),\n",
        "          topk = 5)\n",
        "  \n",
        "  cd_50_HI[key] = cd.score()\n",
        "  cd = None\n",
        "\n",
        "cd_50_HI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*English*"
      ],
      "metadata": {
        "id": "Bil_aX4TtoHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ENGLISH : Centroid Embeddings for 25 topics\n",
        "cd_25_EN = {}\n",
        "\n",
        "for key in topics_25_EN.keys():\n",
        "  if key == 'en':\n",
        "    continue\n",
        "  topic = topics_25_EN[key]\n",
        "  cd = CD(doc_distribution_original_language = topics_25_EN['en'], \n",
        "          doc_distribution_unseen_language = topic, \n",
        "          topics = z_ctm_25_EN.get_topic_lists(25),\n",
        "          topk = 5)\n",
        "  \n",
        "  cd_25_EN[key] = cd.score()\n",
        "\n",
        "cd_25_EN"
      ],
      "metadata": {
        "id": "svDMq5Egtrb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ENGLISH : Centroid Embeddings for 50 topics\n",
        "cd_50_EN = {}\n",
        "\n",
        "for key in topics_50_EN.keys():\n",
        "  if key == 'hi':\n",
        "    continue\n",
        "  topic = topics_50_EN[key]\n",
        "  cd = CD(doc_distribution_original_language = topics_50_EN['en'], \n",
        "          doc_distribution_unseen_language = topic, \n",
        "          topics = z_ctm_50_EN.get_topic_lists(50),\n",
        "          topk = 5)\n",
        "  \n",
        "  cd_50_EN[key] = cd.score()\n",
        "  cd = None\n",
        "\n",
        "cd_50_EN"
      ],
      "metadata": {
        "id": "9knOxB92tsmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obeCKsgJ9gf4"
      },
      "outputs": [],
      "source": [
        "# Store Metrics\n",
        "metrics = {\n",
        "          \"Hindi\" : [{\n",
        "                    \"Mat25\": matches_25_HI,\n",
        "                    \"KL25\": kl_divergence_25_HI, \n",
        "                    \"CD25\": cd_25_HI, \n",
        "                    \"Mat50\": matches_50_HI, \n",
        "                    \"KL50\": kl_divergence_50_HI,\n",
        "                    \"CD50\": cd_50_HI\n",
        "                    }],\n",
        "\n",
        "          \"English\": [{\n",
        "                    \"Mat25\": matches_25_EN,\n",
        "                    \"KL25\": kl_divergence_25_EN, \n",
        "                    \"CD25\": cd_25_EN, \n",
        "                    \"Mat50\": matches_50_EN, \n",
        "                    \"KL50\": kl_divergence_50_EN,\n",
        "                    \"CD50\": cd_50_EN\n",
        "                    }]\n",
        "          }\n",
        "with open(\"metrics_samescript.txt\", 'wb') as F:\n",
        "  pickle.dump(metrics, F)\n",
        "\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Results"
      ],
      "metadata": {
        "id": "lzAMmhgGpTb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show results\n",
        "metrics = {\"Hindi\" : \n",
        "           \n",
        "           {\"Mat25\": matches_25_HI,\n",
        "           \"KL25\": kl_divergence_25_HI, \n",
        "           \"CD25\": cd_25_HI, \n",
        "           \"Mat50\": matches_50_HI, \n",
        "           \"KL50\": kl_divergence_50_HI,\n",
        "           \"CD50\": cd_50_HI},\n",
        "           \n",
        "           \"English\" : \n",
        "           {\"Mat25\": matches_25_EN,\n",
        "           \"KL25\": kl_divergence_25_EN, \n",
        "           \"CD25\": cd_25_EN, \n",
        "           \"Mat50\": matches_50_EN, \n",
        "           \"KL50\": kl_divergence_50_EN,\n",
        "           \"CD50\": cd_50_EN}\n",
        "           }\n",
        "\n",
        "metrics = pd.DataFrame.from_dict(metrics, orient='columns') \n",
        "print(\"Match, KL, and Centroid Similarity for 25 and 50 topics on various languages on PMIndia Corpus\")\n",
        "metrics"
      ],
      "metadata": {
        "id": "4wOmqj7DsXs_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "ZeroshotTM For Same Script Languages",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e23eb79e4164c3e8255377c63c148f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f775ea37dee45dca3bffb64eff854a0",
              "IPY_MODEL_a91e61e3c1d940ddadf35de30dfb7fa0",
              "IPY_MODEL_ec8f81d5a5524203a4c367b043d6e614"
            ],
            "layout": "IPY_MODEL_dd2f6d3ccd9b4afea63498ecfbaca480"
          }
        },
        "8f775ea37dee45dca3bffb64eff854a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c3f57776e9f4942a4c82a304af5edf5",
            "placeholder": "​",
            "style": "IPY_MODEL_c81a3e083f0143218297ac5dfe71debb",
            "value": "Downloading: 100%"
          }
        },
        "a91e61e3c1d940ddadf35de30dfb7fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d9ffb7eb5b1431ebc839c99f0f77e53",
            "max": 507,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e3f423ca41946ec924985017bfec049",
            "value": 507
          }
        },
        "ec8f81d5a5524203a4c367b043d6e614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79de7bbdf8f942f4b429dff85d75d725",
            "placeholder": "​",
            "style": "IPY_MODEL_2b0a015dee53491dbb474ea756f657a3",
            "value": " 507/507 [00:00&lt;00:00, 17.4kB/s]"
          }
        },
        "dd2f6d3ccd9b4afea63498ecfbaca480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c3f57776e9f4942a4c82a304af5edf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c81a3e083f0143218297ac5dfe71debb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d9ffb7eb5b1431ebc839c99f0f77e53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e3f423ca41946ec924985017bfec049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79de7bbdf8f942f4b429dff85d75d725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b0a015dee53491dbb474ea756f657a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87a0c90d741a49028a60d3c80be24091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1769c50f497649a682960530f3879e64",
              "IPY_MODEL_4c02146948c049db98bb33eaeec3365a",
              "IPY_MODEL_8ea6c41758874ed98a5cdc2cef0ba970"
            ],
            "layout": "IPY_MODEL_ee4f46cab385467ab4a876e9ef680ba8"
          }
        },
        "1769c50f497649a682960530f3879e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0904d5bd060447c88aedfdc8945265f4",
            "placeholder": "​",
            "style": "IPY_MODEL_e5523aa1aff0463aaa94f413529df362",
            "value": "Downloading: 100%"
          }
        },
        "4c02146948c049db98bb33eaeec3365a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abb138bc00ac40099e8aec99aff3d2ad",
            "max": 134982446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a95aba2b373469ba968bc0fb1a6449d",
            "value": 134982446
          }
        },
        "8ea6c41758874ed98a5cdc2cef0ba970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c79e1a2958ad43e180f294dc052be80e",
            "placeholder": "​",
            "style": "IPY_MODEL_f9a92e9814a74dc6b1decf03a595cbfa",
            "value": " 129M/129M [00:03&lt;00:00, 66.0MB/s]"
          }
        },
        "ee4f46cab385467ab4a876e9ef680ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0904d5bd060447c88aedfdc8945265f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5523aa1aff0463aaa94f413529df362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abb138bc00ac40099e8aec99aff3d2ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a95aba2b373469ba968bc0fb1a6449d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c79e1a2958ad43e180f294dc052be80e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9a92e9814a74dc6b1decf03a595cbfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "103e4f9ffc914a81919ccb648cb202d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9fe82bfe1d864c86a90e9dc3516b6d90",
              "IPY_MODEL_513981a1cfb641279b8725678956a8ab",
              "IPY_MODEL_57775ccab6214451acae604cad51311e"
            ],
            "layout": "IPY_MODEL_730a4eaa85434a6690b7712ba13d0293"
          }
        },
        "9fe82bfe1d864c86a90e9dc3516b6d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e3ae0d15abc41bb94f4f3fd49bab2ac",
            "placeholder": "​",
            "style": "IPY_MODEL_503a228fc2a941659a7e45d7aadeaff4",
            "value": "Downloading: 100%"
          }
        },
        "513981a1cfb641279b8725678956a8ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63c4e50b6ff240dba2a34a7ab8fceb01",
            "max": 5646064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4212f5bb16794dd59581c7c9cee9e16d",
            "value": 5646064
          }
        },
        "57775ccab6214451acae604cad51311e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3740be0359c14284ad2733df42dc8183",
            "placeholder": "​",
            "style": "IPY_MODEL_ce97ac1976714856be74dfd818b0d62d",
            "value": " 5.38M/5.38M [00:01&lt;00:00, 5.02MB/s]"
          }
        },
        "730a4eaa85434a6690b7712ba13d0293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e3ae0d15abc41bb94f4f3fd49bab2ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "503a228fc2a941659a7e45d7aadeaff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63c4e50b6ff240dba2a34a7ab8fceb01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4212f5bb16794dd59581c7c9cee9e16d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3740be0359c14284ad2733df42dc8183": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce97ac1976714856be74dfd818b0d62d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c19075abef54e8c87ad89fa1f4765e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f27cb8c71d1d47b295890ae04060c4be",
              "IPY_MODEL_13091ff199624ec884a09eef0f4c4d7e",
              "IPY_MODEL_405785406f7448b9a6c25f3f5b892990"
            ],
            "layout": "IPY_MODEL_c5383cb9621c467ea9b1c8f5a82a6387"
          }
        },
        "f27cb8c71d1d47b295890ae04060c4be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7061ce2b0e43401784483cf53b5e6861",
            "placeholder": "​",
            "style": "IPY_MODEL_2748034910894f98904a8ee1680cab35",
            "value": "Batches: 100%"
          }
        },
        "13091ff199624ec884a09eef0f4c4d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22e114a6afcc4b06ae55551ecc32858c",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e25e85b678c749dd954c07bcee9cae09",
            "value": 21
          }
        },
        "405785406f7448b9a6c25f3f5b892990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e61773505a6640ec8bbc6a4713d21634",
            "placeholder": "​",
            "style": "IPY_MODEL_2712074b799d45d08645a72e069b38b6",
            "value": " 21/21 [00:17&lt;00:00,  1.45it/s]"
          }
        },
        "c5383cb9621c467ea9b1c8f5a82a6387": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7061ce2b0e43401784483cf53b5e6861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2748034910894f98904a8ee1680cab35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22e114a6afcc4b06ae55551ecc32858c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e25e85b678c749dd954c07bcee9cae09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e61773505a6640ec8bbc6a4713d21634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2712074b799d45d08645a72e069b38b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "506f57cad5d54e7387c9ffcf4dd0540a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39fdd0608ded46efac9aa5d47adabbe9",
              "IPY_MODEL_463731ab99e742499c2d6778445b8502",
              "IPY_MODEL_8a95e2c364434aa29199787310da4213"
            ],
            "layout": "IPY_MODEL_d8167fa2b1c94e6e932925cd25d62369"
          }
        },
        "39fdd0608ded46efac9aa5d47adabbe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ead59d73f4a549719407dbaf57189e2d",
            "placeholder": "​",
            "style": "IPY_MODEL_e051a17cb3ea4157bf5ddc7e150c28c0",
            "value": "Batches: 100%"
          }
        },
        "463731ab99e742499c2d6778445b8502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fda3699f6dbc4b38b8baf20c26994071",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_104a4429b90949f7a812242174c8e274",
            "value": 22
          }
        },
        "8a95e2c364434aa29199787310da4213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad805e7a622346ba9973f59293c1ac1d",
            "placeholder": "​",
            "style": "IPY_MODEL_993930b9455f4efaa440dd65ac147093",
            "value": " 22/22 [00:21&lt;00:00,  1.40s/it]"
          }
        },
        "d8167fa2b1c94e6e932925cd25d62369": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ead59d73f4a549719407dbaf57189e2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e051a17cb3ea4157bf5ddc7e150c28c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fda3699f6dbc4b38b8baf20c26994071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "104a4429b90949f7a812242174c8e274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad805e7a622346ba9973f59293c1ac1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "993930b9455f4efaa440dd65ac147093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}