{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Existing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wu5clpV2xyLL"
   },
   "source": [
    "## CCAligned: A Massive Collection of Cross-Lingual Web-Document Pairs\n",
    "\n",
    "* https://aclanthology.org/2020.emnlp-main.480.pdf\n",
    "* https://www.statmt.org/cc-aligned/\n",
    "\n",
    "**Summary**\n",
    "\n",
    "CCAligned consists of *parallel or comparable web-document pairs in 137 languages aligned with English*. \n",
    "\n",
    "These web-document pairs were constructed by performing language identification on raw web-documents, and ensuring corresponding language codes were corresponding in the URLs of web documents. \n",
    "\n",
    "This pattern matching approach yielded more than 100 million aligned documents paired with English. Recognizing that each English document was often aligned to mulitple documents in different target language, we can join on English documents to obtain aligned documents that directly pair two non-English documents (e.g., Arabic-French)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aw99jFKZy34j",
    "outputId": "1f536233-648d-40d2-f03a-d294068d11b2"
   },
   "outputs": [],
   "source": [
    "!mkdir hindi tamil # directory to store hindi and tamil data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cb2_3kw725EM",
    "outputId": "a9f89f23-cc00-4125-fe2f-c0c4f9eae2b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  3 1453M    3 44.9M    0     0  2602k      0  0:09:31  0:00:17  0:09:14 8840k"
     ]
    }
   ],
   "source": [
    "# Download Hindi-English Document Aligned Corpus\n",
    "!curl -O https://data.statmt.org/cc-aligned/en_XX-hi_IN.tsv.xz\n",
    "\n",
    "# Download Tamil-English Document Aligned Corpus\n",
    "!curl -O https://data.statmt.org/cc-aligned/en_XX-ta_IN.tsv.xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQmE7iSFzi3Y"
   },
   "outputs": [],
   "source": [
    "# Unzip Hindi-English Aligned Documents\n",
    "!xz -d -k -f -c en_XX-hi_IN.tsv.xz > /content/hindi/en_XX-hi_IN.tsv\n",
    "\n",
    "# Unzip Tamil-English Aligned Documents\n",
    "!xz -d -k -f -c en_XX-ta_IN.tsv.xz > /content/tamil/en_XX-ta_IN.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_i6Exn6z2aKb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/content/hindi/en_XX-hi_IN.tsv', delimiter='\\t', encoding='utf-8')\n",
    "\n",
    "# Access individual columns using column names\n",
    "column_names = data.columns\n",
    "print(column_names)\n",
    "\n",
    "# Process the data as needed\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6dA1laLQfka"
   },
   "source": [
    "# **Building Datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Approach**\n",
    "\n",
    "Let's write a script to randomly select 20,000 Wikipedia articles in Tamil from Tamil Wikipedia and extract their title, URI. I will then loop through this list to check if we have its version in Hindi and English.\n",
    "\n",
    "My assumption is that if an article exists in Tamil which is the lesser of the 3 languages in terms of data availability, then those articles will likely be in Hindi and certainly in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hBN5EVmChvBD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (21.2.4)\n",
      "Collecting pip\n",
      "  Downloading pip-23.1.2-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.2.4\n",
      "    Uninstalling pip-21.2.4:\n",
      "      Successfully uninstalled pip-21.2.4\n",
      "Successfully installed pip-23.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.8/dist-packages (0.5.8)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from wikipedia-api) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->wikipedia-api) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->wikipedia-api) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->wikipedia-api) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->wikipedia-api) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting mwclient\n",
      "  Downloading mwclient-0.10.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.8/dist-packages (from mwclient) (1.3.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from mwclient) (1.16.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib->mwclient) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib->mwclient) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->requests-oauthlib->mwclient) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->requests-oauthlib->mwclient) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->requests-oauthlib->mwclient) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->requests-oauthlib->mwclient) (2022.12.7)\n",
      "Installing collected packages: mwclient\n",
      "Successfully installed mwclient-0.10.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting SPARQLWrapper\n",
      "  Downloading SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\n",
      "Collecting rdflib>=6.1.1 (from SPARQLWrapper)\n",
      "  Downloading rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting isodate<0.7.0,>=0.6.0 (from rdflib>=6.1.1->SPARQLWrapper)\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m207.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.0.9)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->SPARQLWrapper) (1.16.0)\n",
      "Installing collected packages: isodate, rdflib, SPARQLWrapper\n",
      "Successfully installed SPARQLWrapper-2.0.0 isodate-0.6.1 rdflib-6.3.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install wikipedia-api\n",
    "!pip install mwclient\n",
    "!pip install SPARQLWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ew2YWpB7Qjhk"
   },
   "source": [
    "## **Number of Articles in Wikipedia**\n",
    "\n",
    "As of May 17, 2023:\n",
    "1. Tamil Wikipedia has **153,998** articles.\n",
    "2. Hindi Wikipedia has **156,511** articles. \n",
    "3. English Wikipedia has **6,657,489** articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cv5ziOyAQkWR",
    "outputId": "e674ce1b-462e-4e86-ce6c-7b88cd1057a5"
   },
   "outputs": [],
   "source": [
    "# CODE BY CHATGPT 3.5\n",
    "import requests\n",
    "import locale\n",
    "\n",
    "def get_article_count(language):\n",
    "    url = f\"https://{language}.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"meta\": \"siteinfo\",\n",
    "        \"siprop\": \"statistics\",\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    return data[\"query\"][\"statistics\"][\"articles\"]\n",
    "\n",
    "# Set the locale to use comma as a thousands separator\n",
    "locale.setlocale(locale.LC_ALL, \"\")\n",
    "\n",
    "# Get number of articles in Tamil Wikipedia\n",
    "tamil_count = int(get_article_count(\"ta\"))\n",
    "formatted_tamil_count = locale.format_string(\"%d\", tamil_count, grouping=True)\n",
    "print(\"Number of articles in Tamil Wikipedia:\", formatted_tamil_count)\n",
    "\n",
    "# Get number of articles in Hindi Wikipedia\n",
    "hindi_count = int(get_article_count(\"hi\"))\n",
    "formatted_hindi_count = locale.format_string(\"%d\", hindi_count, grouping=True)\n",
    "print(\"Number of articles in Hindi Wikipedia:\", formatted_hindi_count)\n",
    "\n",
    "# Get number of articles in English Wikipedia\n",
    "english_count = int(get_article_count(\"en\"))\n",
    "formatted_english_count = locale.format_string(\"%d\", english_count, grouping=True)\n",
    "print(\"Number of articles in English Wikipedia:\", formatted_english_count)\n",
    "\n",
    "print(article_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOI5ZM23Rdw9"
   },
   "source": [
    "## **Requirement**\n",
    "The dataset is a **3-way comparable corpora in English-Hindi-Tamil**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnAgjP4uRfn8"
   },
   "source": [
    "\n",
    "\n",
    "### **W1** (n = 20,000)\n",
    "* For comparing monolingual models using Neural-ProdLDA, LDA with ZershotTM in each language - hi, en, ta.\n",
    "* For calculating NPMI Coherence score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImvG1BHPKPyB"
   },
   "source": [
    "### **W2** (n = 100,000)\n",
    "\n",
    "**METRICS FOR EVALUATION**\n",
    "* *Matches (Mat)*\n",
    "* *KL Divergence (KL)*\n",
    "* *Centroid Embeddings (CD)*\n",
    "\n",
    "**AUTOMATIC EVALUATION**\n",
    "\n",
    "*Baseline 1 (Ori)*\n",
    "\n",
    "* Performs topic modeling on documents translated into English via DeepL.\n",
    "* This is an easily accessible baseline, but automatic translation may introduce bias in the representations.\n",
    "\n",
    "*Baseline 2 (Uni)*\n",
    "\n",
    "* Computes all the metrics over a uniform distribution.\n",
    "* This baseline gives a lower bound.\n",
    "\n",
    "**MANUAL EVALUATION**\n",
    "\n",
    "*Rating of Predicted Topics*\n",
    "\n",
    "* We rated the predicted topics for 300 test documents in five languages on an ordinal scale from 0-3.\n",
    "* A 0 rate means that the predicted topic is wrong, a 1 rate means the topic is somewhat related, a 2 rate means the topic is good, and a 3 rate means the topic is entirely associated with the considered document.\n",
    "\n",
    "*Inter-rater Reliability*\n",
    "\n",
    "* We evaluated the inter-rater reliability using Gwet AC1 with ordinal weighting.\n",
    "* The resulting value of 0.88 indicates consistent scoring.\n",
    "\n",
    "## **Approach**\n",
    "\n",
    "Let's write a script to randomly select 20,000 Wikipedia articles in Tamil from Tamil Wikipedia and extract their title, URI. I will then loop through this list to check if we have its version in Hindi and English.\n",
    "\n",
    "My assumption is that if an article exists in Tamil which is the lesser of the 3 languages in terms of data availability, then those articles will likely be in Hindi and certainly in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwaJ6ZhmVjF6",
    "outputId": "39f25158-13c9-41ee-cc97-8c4eac02f04a"
   },
   "outputs": [],
   "source": [
    "!pip install mwapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R8Zb3fBfVlRc",
    "outputId": "23833ee1-6524-459c-b1c4-09de9850985b"
   },
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "import wikipedia\n",
    "import random\n",
    "\n",
    "article_counts = {'ta': tamil_count, 'hi': hindi_count, 'en': english_count}\n",
    "\n",
    "# Total counts of articles for each language\n",
    "total_counts = article_counts\n",
    "\n",
    "# Language codes\n",
    "languages = ['ta', 'hi', 'en']\n",
    "\n",
    "# Number of articles to select\n",
    "num_articles = 20\n",
    "\n",
    "# Set the seed for random number generation for reproducibility\n",
    "random.seed(20)\n",
    "\n",
    "# Initialize lists to store the titles and URIs of selected articles\n",
    "titles = []\n",
    "uris = []\n",
    "\n",
    "import mwapi\n",
    "\n",
    "session = mwapi.Session(\"https://{lang}.wikipedia.org\".format(lang=languages[0]))\n",
    "\n",
    "# Returns titles of Wikipedia articles\n",
    "def get_article(title):\n",
    "    response = session.get(action=\"query\", prop=\"info\", titles=title, formatversion=2)\n",
    "    pages = response['query']['pages']\n",
    "    for page in pages:\n",
    "        if 'title' in page:\n",
    "            return page['title']\n",
    "    return None\n",
    "\n",
    "# Set language to Tamil\n",
    "wikipedia.set_lang('ta')\n",
    "\n",
    "# Get a random page in Tamil\n",
    "random_pages = [wikipedia.random(1) for _ in range(20)]\n",
    "\n",
    "# Print the titles of the randomly selected articles\n",
    "titles = [page for page in random_pages]\n",
    "for page in random_pages:\n",
    "    print(\"Article Title:\", page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rN7VbtqxZVcW",
    "outputId": "184ffbc4-f35c-44cd-d18f-758500ad0e38"
   },
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "# Set language to Tamil\n",
    "wiki_wiki = wikipediaapi.Wikipedia('ta')\n",
    "\n",
    "enc = 0\n",
    "hic = 0\n",
    "tot = 0\n",
    "# Get the page for titles in Tamil Wikipedia\n",
    "for title in titles:\n",
    "    page = wiki_wiki.page(title)\n",
    "\n",
    "    # Check if the article exists in English and Hindi\n",
    "    exists_en = False\n",
    "    exists_hi = False\n",
    "    if 'hi' in page.langlinks:\n",
    "        exists_hi = True\n",
    "        hic +=1\n",
    "    if 'en' in page.langlinks:\n",
    "        exists_en = True\n",
    "        enc += 1\n",
    "\n",
    "    # Print the result\n",
    "    if exists_hi and exists_en:\n",
    "        tot += 1\n",
    "        print(\"hi/en yes\")\n",
    "print(\"Total: \" + str(tot))\n",
    "print(hic, enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "WWSBgjMvd1AQ",
    "outputId": "991593be-7d9d-44bb-a74b-6e225a78edbf"
   },
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "import random\n",
    "\n",
    "random.seed(10)\n",
    "# Set language to Tamil\n",
    "wiki_tamil = wikipediaapi.Wikipedia('ta')\n",
    "\n",
    "enc = 0\n",
    "hic = 0\n",
    "tot = 0\n",
    "count = 0  # Counter for the number of articles\n",
    "\n",
    "# List to store the retrieved article titles\n",
    "article_titles = []\n",
    "\n",
    "# Keep retrieving articles until count reaches 100\n",
    "while count < 100:\n",
    "    # Get a random index within the range of the total number of articles in Tamil Wikipedia\n",
    "    random_index = random.randint(1, total_counts['ta'])\n",
    "    \n",
    "    # Create the title of the article using the random index\n",
    "    title = \"பகுப்பு:\" + str(random_index)\n",
    "    \n",
    "    # Check if the article exists in English and Hindi\n",
    "    exists_en = False\n",
    "    exists_hi = False\n",
    "    \n",
    "    # Get the page for the article\n",
    "    page = wiki_tamil.page(title)\n",
    "    \n",
    "    # if 'hi' in page.langlinks:\n",
    "    #     exists_hi = True\n",
    "    #     hic += 1\n",
    "    #     print(\"yes\")\n",
    "    # if 'en' in page.langlinks:\n",
    "    #     exists_en = True\n",
    "    #     enc += 1\n",
    "\n",
    "    if 'hi' in page.langlinks and 'en' in page.langlinks:\n",
    "        exists_hi = exists_en = True\n",
    "        hic += 1\n",
    "        enc += 1\n",
    "\n",
    "    # If the article exists in both English and Hindi, increment the counter\n",
    "    if exists_hi and exists_en:\n",
    "        count += 1\n",
    "\n",
    "        # Append the title to the article_titles list\n",
    "        article_titles.append(title)\n",
    "\n",
    "# Print the retrieved article titles\n",
    "for title in article_titles:\n",
    "    print(\"Title:\", title)\n",
    "\n",
    "# Print the final count\n",
    "print(\"Total articles:\", count)\n",
    "print(\"Hindi articles:\", hic)\n",
    "print(\"English articles:\", enc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBlIBZobYkP3",
    "outputId": "e7b17226-13a2-4580-ccbd-f4d93dc7c869"
   },
   "outputs": [],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9kRCMBGYB57"
   },
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "import wikipedia\n",
    "\n",
    "wiki_tamil = wikipediaapi.Wikipedia('ta')\n",
    "\n",
    "# Function to check if an article exists in a given language\n",
    "def check_article_exists(title, language):\n",
    "    try:\n",
    "        page = wikipedia.page(title)\n",
    "        language_links = page.language_links\n",
    "        return language in language_links\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        return False\n",
    "\n",
    "# Loop through the list of Tamil articles\n",
    "for index in article_indices:\n",
    "    title = \"பகுப்பு:{index}\".format(index=index)\n",
    "    \n",
    "    # Check if the article exists in Hindi\n",
    "    exists_hi = check_article_exists(title, 'hi')\n",
    "    \n",
    "    # Check if the article exists in English\n",
    "    exists_en = check_article_exists(title, 'en')\n",
    "    \n",
    "    # Print the article title and its availability in Hindi and English\n",
    "    print(f\"Article Title: {title}\")\n",
    "    print(f\"Available in Hindi: {exists_hi}\")\n",
    "    print(f\"Available in English: {exists_en}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LooLrxlKyHZh"
   },
   "source": [
    "## Comparable Corpus Creation from Wikipedia\n",
    "\n",
    "This will be a novel contribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPI-g9oTgikY"
   },
   "outputs": [],
   "source": [
    "QUERY = \"\"\" PREFIX dbpedia-owl: <http://dbpedia.org/ontology/>\n",
    "PREFIX dbr: <http://dbpedia.org/resource/>\n",
    "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\n",
    "SELECT ?article ?tamil_abstract WHERE {\n",
    "    \n",
    "    ?article dbo:abstract ?tamil_abstract . \n",
    "    FILTER (lang(?tamil_abstract) = \"hi\")\n",
    "}\n",
    "LIMIT 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zr3ol_tsgm5L",
    "outputId": "944d3ad4-bbde-4fd6-f925-6d2a6ef39777"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setQuery(QUERY)\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ufn11swIgtRk",
    "outputId": "185bccea-0d4d-47bd-caa1-894a66e4f80d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ZeC-BpmvCAl",
    "outputId": "deda4269-3bfa-4d68-a168-54a0288bc41b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article is available in Tamil\n"
     ]
    }
   ],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "# Set language to English\n",
    "wiki_wiki = wikipediaapi.Wikipedia('en')\n",
    "\n",
    "# Get the page for \"India\"\n",
    "page = wiki_wiki.page(\"India\")\n",
    "\n",
    "# Check if the article exists in Tamil\n",
    "exists_ta = False\n",
    "if 'ta' in page.langlinks:\n",
    "    exists_ta = True\n",
    "\n",
    "# Print the result\n",
    "if exists_ta:\n",
    "    print(\"Article is available in Tamil\")\n",
    "else:\n",
    "    print(\"Article is not available in Tamil\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S34OpiSo3K7l",
    "outputId": "86c8dc50-2efd-4099-b33b-52a022d509c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary (English):\n",
      "India, officially the Republic of India (ISO: Bhārat Gaṇarājya), is a country in South Asia. It is the seventh-largest country by area, the most populous country as of 1 May 2023, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand, Myanmar, and Indonesia. \n",
      "Modern humans arrived on the Indian subcontinent from Africa no later than 55,000 years ago.\n",
      "Their long occupation, initially in varying forms of isolation as hunter-gatherers, has made the region highly diverse, second only to Africa in human genetic diversity. Settled life emerged on the subcontinent in the western margins of the Indus river basin 9,000 years ago, evolving gradually into the Indus Valley Civilisation of the third millennium BCE.\n",
      "By 1200 BCE, an archaic form of Sanskrit, an Indo-European language, had diffused into India from the northwest. Its evidence today is found in the hymns of the Rigveda. Preserved by a resolutely vigilant oral tradition, the Rigveda records the dawning of Hinduism in India. The Dravidian languages of India were supplanted in the northern and western regions.\n",
      "By 400 BCE, stratification and exclusion by caste had emerged within Hinduism,\n",
      "and Buddhism and Jainism had arisen, proclaiming social orders unlinked to heredity.\n",
      "Early political consolidations gave rise to the loose-knit Maurya and Gupta Empires based in the Ganges Basin.\n",
      "Their collective era was suffused with wide-ranging creativity, but also marked by the declining status of women, and the incorporation of untouchability into an organised system of belief. In South India, the Middle kingdoms exported Dravidian-languages scripts and religious cultures to the kingdoms of Southeast Asia.In the early medieval era, Christianity, Islam, Judaism, and Zoroastrianism became established on India's southern and western coasts.\n",
      "Muslim armies from Central Asia intermittently overran India's northern plains,\n",
      "eventually founding the Delhi Sultanate, and drawing northern India into the cosmopolitan networks of medieval Islam.\n",
      "In the 15th century, the Vijayanagara Empire created a long-lasting composite Hindu culture in south India.\n",
      "In the Punjab, Sikhism emerged, rejecting institutionalised religion.\n",
      "The Mughal Empire, in 1526, ushered in two centuries of relative peace,\n",
      "leaving a legacy of luminous architecture.\n",
      "Gradually expanding rule of the British East India Company followed, turning India into a colonial economy, but also consolidating its sovereignty. British Crown rule began in 1858. The rights promised to Indians were granted slowly, but technological changes were introduced, and modern ideas of education and the public life took root. A pioneering and influential nationalist movement emerged, which was noted for nonviolent resistance and became the major factor in ending British rule. In 1947 the British Indian Empire was partitioned into two independent dominions, a Hindu-majority Dominion of India and a Muslim-majority Dominion of Pakistan, amid large-scale loss of life and an unprecedented migration.India has been a federal republic since 1950, governed through a democratic parliamentary system. It is a pluralistic, multilingual and multi-ethnic society. India's population grew from 361 million in 1951 to almost 1.4 billion in 2022.\n",
      "During the same time, its nominal per capita income increased from US$64 annually to US$1,498, and its literacy rate from 16.6% to 74%. From being a comparatively destitute country in 1951,\n",
      "India has become a fast-growing major economy and a hub for information technology services, with an expanding middle class. It has a space programme which includes several planned or completed extraterrestrial missions. Indian movies, music, and spiritual teachings play an increasing role in global culture.\n",
      "India has substantially reduced its rate of poverty, though at the cost of increasing economic inequality.\n",
      "India is a nuclear-weapon state, which ranks high in military expenditure. It has disputes over Kashmir with its neighbours, Pakistan and China, unresolved since the mid-20th century.\n",
      "Among the socio-economic challenges India faces are gender inequality, child malnutrition,\n",
      "and rising levels of air pollution.\n",
      "India's land is megadiverse, with four biodiversity hotspots. Its forest cover comprises 21.7% of its area. India's wildlife, which has traditionally been viewed with tolerance in India's culture, is supported among these forests, and elsewhere, in protected habitats.\n",
      "Summary (Hindi):\n",
      "भारत (आधिकारिक नाम: भारत गणराज्य, अंग्रेज़ी: Republic of India) दक्षिण एशिया में स्थित भारतीय उपमहाद्वीप का सबसे बड़ा देश है। भारत भौगोलिक दृष्टि से विश्व का सातवाँ सबसे बड़ा देश है, जबकि जनसंख्या के दृष्टिकोण से चीन के बाद दूसरा सबसे बड़ा देश है। भारत के पश्चिम में पाकिस्तान, उत्तर-पूर्व में चीन (तिब्बत), नेपाल और भूटान, पूर्व में बांग्लादेश और म्यान्मार स्थित हैं। भारतीय महासागर में इसके दक्षिण पश्चिम में मालदीव, दक्षिण में श्रीलंका और दक्षिण-पूर्व में इंडोनेशिया से भारत की सामुद्रिक सीमा लगती है। इसके उत्तर में हिमालय पर्वत तथा दक्षिण में भारतीय महासागर स्थित है। दक्षिण-पूर्व में बंगाल की खाड़ी तथा पश्चिम में अरब सागर है।\n",
      "आधुनिक मानव या होमो सेपियंस अफ्रीका से भारतीय उपमहाद्वीप में 55,000 साल पहले आये थे।  1,000 वर्ष पहले ये सिंधु नदी के पश्चिमी हिस्से की तरफ बसे हुए थे जहाँ से इन्होने धीरे धीरे पलायन किया और सिंधु घाटी सभ्यता के रूप में विकसित हुए।  1,200 ईसा पूर्व संस्कृत भाषा संपूर्ण भारतीय उपमहाद्वीप में फैली हुए थी और तब तक यहाँ पर हिंदू धर्म का उद्धव हो चुका था और ऋग्वेद की रचना भी हो चुकी थी।  400 ईसा पूर्व तक आते आते हिंदू धर्म में जातिवाद देखने को मिल जाता है।  इसी समय बौद्ध एवं जैन धर्म उत्पन्न हो रहे होते हैं।\n",
      "\n",
      "प्रारंभिक राजनीतिक एकत्रीकरण ने गंगा बेसिन में स्थित मौर्य और गुप्त साम्राज्यों को जन्म दिया।\n",
      "उनका समाज विस्तृत सृजनशीलता से भरा हुआ था। प्रारंभिक मध्ययुगीन काल में, ईसाई धर्म, इस्लाम, यहूदी धर्म और पारसी धर्म ने भारत के दक्षिणी और पश्चिमी तटों पर जड़ें जमा लीं। मध्य एशिया से मुस्लिम सेनाओं ने भारत के उत्तरी मैदानों पर लगातार अत्याचार किया, अंततः दिल्ली सल्तनत की स्थापना हुई और उत्तर भारत को मध्यकालीन इस्लाम साम्राज्य में मिला लिया गया।\n",
      " 15 वीं शताब्दी में, विजयनगर साम्राज्य ने दक्षिण भारत में एक लंबे समय तक चलने वाली समग्र हिंदू संस्कृति बनाई। पंजाब में सिख धर्म की स्थापना हुई।  धीरे-धीरे ब्रिटिश ईस्ट इंडिया कंपनी के शासन का विस्तार हुआ, जिसने भारत को औपनिवेशिक अर्थव्यवस्था में बदल दिया तथा अपनी संप्रभुता को भी मजबूत किया। ब्रिटिश राज शासन 1858 में शुरू हुआ। धीरे धीरे एक प्रभावशाली राष्ट्रवादी आंदोलन शुरू हुआ जिसे अहिंसक विरोध के लिए जाना गया और ब्रिटिश शासन को समाप्त करने का प्रमुख कारक बन गया।  1947 में ब्रिटिश भारतीय साम्राज्य को दो स्वतंत्र प्रभुत्वों में विभाजित किया गया, भारतीय अधिराज्य तथा पाकिस्तान अधिराज्य, जिन्हे धर्म के आधार पर विभाजित किया गया। 1950 से भारत एक संघीय गणराज्य है। भारत की जनसंख्या 1951 में 36.1 करोड़ से बढ़कर 2011 में 121.1 करोड़ हो गई। प्रति व्यक्ति आय $64 से बढ़कर $1,498 हो गई और इसकी साक्षरता दर 16.6% से 74% हो गई। भारत एक तेजी से बढ़ती हुई प्रमुख अर्थव्यवस्था और सूचना प्रौद्योगिकी सेवाओं का केंद्र बन गया है।  अंतरिक्ष क्षेत्र में भारत ने उल्लेखनीय तथा अद्वितीय प्रगति की। भारतीय फिल्में, संगीत और आध्यात्मिक शिक्षाएँ वैश्विक संस्कृति में विशेष भूमिका निभाती हैं।  भारत ने गरीबी दर को काफी हद तक कम कर दिया है। भारत देश परमाणु बम रखने वाला देश है। कश्मीर तथा भारत-पाकिस्तान और भारत-चीन सीमा पर भारत का पाकिस्तान तथा चीन से विवाद चल रहा है। लैंगिक असमानता, बाल शोषण, बाल कुपोषण, गरीबी, भ्रष्टाचार, प्रदूषण इत्यादि भारत के सामने प्रमुख चुनौतियाँ है। 21.4% क्षेत्र पर वन है। भारत के वन्यजीव, जिन्हें परंपरागत रूप से भारत की संस्कृति में सहिष्णुता के साथ देखा गया है, इन जंगलों और अन्य जगहों पर संरक्षित आवासों में निवास करते हैं।\n",
      "12 फरवरी वर्ष 1948 में महात्मा गाँधी के अस्थि कलश जिन 12 तटों पर विसर्जित किए गए थे, त्रिमोहिनी संगम भी उनमें से एक है |\n",
      "Summary (Tamil):\n",
      "இந்தியா (ஆங்கிலம்: India), அதிகாரபூர்வமாக இந்தியக் குடியரசு (Republic of India), தெற்காசியாவில் உள்ள ஒரு குடியரசு நாடாகும். இந்திய துணைக்கண்டத்தின் பெரும் பகுதியைத் தன்னுள் அடக்கியுள்ளது. இந்தியா என்ற பெயர் நாவலந்தேயம் என்னும் பெயரிலிருந்து பெறப்பட்டது. சிலர் சிந்து நதியில் இருந்து பெறப்பட்டதாகச் சொல்லுவதுண்டு. சிந்து நதியில்  பெறப்பட்டது இந்து ஆகும். இந்தியப் பெருநிலம் தெற்கே இந்தியப் பெருங்கடல், மேற்கே அரபிக் கடல், கிழக்கே வங்காள விரிகுடா ஆகியவற்றைக் கொண்டுள்ளது. இதன் எல்லை நாடுகளாக மேற்கே பாக்கித்தான், வடக்கே பூட்டான், மக்கள் சீனக் குடியரசு, நேபாளம், கிழக்கே வங்காளதேசம், மியான்மர் ஆகியவை அமைந்துள்ளன. இலங்கை, மற்றும் மாலத்தீவு ஆகிய நாடுகள் இந்தியப் பெருங்கடலில் இந்தியப் பெருநிலம், மற்றும் இலட்சத்தீவுகளுக்கு அண்மையில் அமைந்துள்ளன. இந்தியாவின் அந்தமான் நிக்கோபார் தீவுகள், தாய்லாந்து, இந்தோனேசியாவின் சுமாத்திரா ஆகியவற்றுடன் அந்தமான் கடலில் கடல் எல்லையைக் கொண்டுள்ளன.பரப்பளவில் இந்தியா ஏழாவது இடத்தில் உள்ள நாடு. இந்தியா மொத்தம் 7,517 கிமீ (4,700 மைல்) நீளக் கடல் எல்லைக் கொண்டது. 2011 மக்கள் தொகை கணக்கெடுப்பின் படி  நூற்று இருபத்தொரு கோடி மக்கள் தொகையைக் கொண்டு உலகின் இரண்டாமிடத்தில் இந்தியா உள்ளது.பொருளாதாரத்தில் பொருள் வாங்குதிறன் சமநிலை அடிப்படையில் நான்காவது இடத்தில் இருக்கின்றது. உலகின் பண்டைய நாகரிகங்களில் இந்தியாவும் ஒன்று ஆகும். சிந்து சமவெளி நாகரிகம் அல்லது அரப்பா-மொகஞ்சதாரோ என்று அழைக்கப்படும் நாகரிகம் இங்கு தோன்றியது ஆகும்.\n",
      "இந்து சமயம், புத்தம், சமணம், மற்றும் சீக்கியம் ஆகிய நான்கு தலைமை மதங்கள் இந்தியாவிலேயே தோன்றின. பதினேழாம் நூற்றாண்டில் ஐரோப்பிய நாடுகளினால் கைப்பற்றப்பட்டு, 1947 ஆகத்து 15 அன்று விடுதலை பெற்றது. பின்னர் 1950 சனவரி 26 அன்று குடியரசாக அறிவிக்கப்பட்டு உலகின் மிகப்பெரிய குடியரசு நாடாகத் திகழ்கிறது.\n",
      "இந்தியக் குடியரசுத் தலைவர் ஆணையின் பேரில் 2019 அக்டோபர் 31 அன்று இந்தியாவின் புதிய வரைபடம் வெளியிடப்பட்டது.\n"
     ]
    }
   ],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "# Create a Wikipedia API object\n",
    "wiki_wiki = wikipediaapi.Wikipedia('en')\n",
    "\n",
    "# Retrieve the article in English\n",
    "page_en = wiki_wiki.page(\"India (country)\")\n",
    "summary_en = page_en.summary\n",
    "print(\"Summary (English):\")\n",
    "print(summary_en)\n",
    "\n",
    "# Retrieve the article in Hindi\n",
    "wiki_wiki = wikipediaapi.Wikipedia('hi')\n",
    "page_hi = wiki_wiki.page(\"भारत\")\n",
    "summary_hi = page_hi.summary\n",
    "print(\"Summary (Hindi):\")\n",
    "print(summary_hi)\n",
    "\n",
    "# Retrieve the article in Tamil\n",
    "wiki_wiki = wikipediaapi.Wikipedia('ta')\n",
    "page_ta = wiki_wiki.page(\"இந்தியா\")\n",
    "summary_ta = page_ta.summary\n",
    "print(\"Summary (Tamil):\")\n",
    "print(summary_ta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1ubM_aog1Ud"
   },
   "outputs": [],
   "source": [
    "\n",
    "# article_indices = random.sample(range(1, total_counts['ta'] + 1), num_articles)\n",
    "\n",
    "# # \"பகுப்பு:{index}\" represents an article title in the form of \"Category:index\" or \"Category followed by the index number\"\n",
    "# for index in article_indices:\n",
    "#     title = \"பகுப்பு:{index}\".format(index=index)\n",
    "#     article = get_article(title)\n",
    "#     # Process the article as needed\n",
    "#     print(article)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
